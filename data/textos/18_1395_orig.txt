BREVE HISTORIA DE LA INGENIERIA MECANICAINTRODUCCIÓN Antes de mediados del siglo XVIII los trabajos de construcción a gran escala se ponían en manos de los ingenieros militares. La ingeniería militar englobaba tareas tales como la preparación de mapas topográficos, la ubicación, diseño y construcción de carreteras y puentes, y la construcción de fuertes y muelles. Sin embargo, en el siglo XVIII se empezó a utilizar el término ingeniería civil o de caminos para designar a los trabajos de ingeniería efectuados con propósitos no militares. Debido al aumento de la utilización de maquinaria en el siglo XIX como consecuencia de la Revolución Industrial, la ingeniería mecánica se consolidó como rama independiente de la ingeniería; posteriormente ocurrió lo mismo con la ingeniería de minas. Los avances técnicos del siglo XIX ampliaron en gran medida el campo de la ingeniería e introdujeron un gran número de especializaciones. Las incesantes demandas del entorno socioeconómico del siglo XX han incrementado aún más su campo de acción; y se ha producido una gran diferenciación de disciplinas, con distinción de múltiples ramas en ámbitos tales como la aeronáutica, la química, la construcción naval, de caminos, canales y puertos, las telecomunicaciones, la electrónica, la ingeniería industrial, naval, militar, de minas y geología e informática. Además en los últimos tiempos se han incorporado campos del conocimiento que antes eran ajenos a la ingeniería como la investigación genética y nuclear. El ingeniero que desarrolla su actividad en una de las ramas o especialización de la ingeniería ha de tener conocimientos básicos de otras áreas afines, ya que muchos problemas que se presentan en ingeniería son complejos y están interrelacionados. Por ejemplo, un ingeniero químico que tiene que diseñar una planta para el refinamiento electrolítico de minerales metálicos debe enfrentarse al diseño de estructuras, maquinaria, dispositivos eléctricos, además de los problemas estrictamente químicos La Ingeniería Mecánica propiamente dicha reúne todos los conocimientos científicos y técnicos para la dirección de la producción, la conservación y la reparación de maquinaria e instalaciones, equipos y sistemas de producción industrial, así como el estudio tecnológico especializado de diferentes materiales, productos o procesos; la proyección de máquinas herramientas para la industria manufacturera, minera y construcción y otras fines industriales como la agricultura. Estudia la proyección de máquinas de vapor, motores de combustión interna y otras máquinas y motores no eléctricos, utilizados para propulsar locomotoras de ferrocarriles, vehículos de transporte por carretera o aeronaves o para hacer funcionar instalaciones industriales, los sistemas de propulsión para buques, centrales generadoras de energía, sistemas de calefacción y ventilación, bombas, cascos y superestructuras de buques, fuselajes y trenes de aterrizaje y otros equipos para aeronaves, carrocerías, sistemas de suspensión y frenos para vehículos automotores. Estudia el diseño y montaje de sistemas y equipos de calefacción, ventilación y refrigeración; instalaciones y equipos mecánicos para la producción, control y utilización de energía nuclear. Implementa y estudia el diseño de partes o elementos (salvo los eléctricos o electrónicos) de aparatos o productos como procesadores de texto, ordenadores, instrumentos de precisión, cámaras y proyectores; especifica y verifica métodos de producción o instalación y el funcionamiento de maquinaria agrícola y de otras máquinas, mecanismos, herramientas, motores, instalaciones o equipos industriales; el establecimiento de normas y procedimientos de control para garantizar la seguridad y el funcionamiento eficaz.  EDADES DE PIEDRA, HIERRO Y BRONCE: El hombre paleolítico, compañero del mamut y el reno, vivió siempre asediado por el hielo, que con sólo algunas intermitencias dejó de cubrir el norte y centro de Europa y Asia. Fue pues de diez milenios el periodo durante el cual el hombre satisfizo todas las necesidades de su vida con el sílex. Fue lo único que elaboró desconchándolo y retocando sus bordes haciendo saltar astillas. Emociona pensar que por tanto tiempo sólo empleó la piedra de sílex como primera y única materia. No hay nada en la tierra que haya procurado tantos bienes a la humanidad. Se cambió la forma de los sílex, se vio el predominio o la moda de ciertas tallas, hubo épocas en que los sílex fueron grandes como cuchillos y martillos, otras en que se prefirieron hojas como navajas transparentes, pero siempre el sílex, el sílex duro, impenetrable aunque frágil, tuvo que atender a todos los servicios. Desde mediados del siglo pasado empleamos tantos nuevos materiales para la industria, tantos artefactos movidos por vapor y electricidad, que acongoja pensar que nuestros antepasados tuvieron que valerse de sólo la piedra pedernal, el casi santo sílex, por miles y miles de años. Con la época siguiente de la piedra pulimentada, ya pudo el hombre escoger basaltos y otras rocas volcánicas para hacer hachas de piedra pulimentada, pero en la época paleolítica sólo el sílex amarillento, de color cerúleo, lechoso, fue utilizado como empleamos ahora los metales y el vidrio. PRIMEROS ARTILUGIOS MECÁNICOS: CHINA, EGIPTO, GRECIA: El antiguo Dios de Egipto, TOT, era recordado y venerado como inventor de las matemáticas, la astronomía y la ingeniería. A través de su voluntad y poder, mantenía las fuerzas del Cielo y la Tierra en equilibrio. Sus grandes dotes para las matemáticas celestiales le permitieron aplicar correctamente las leyes sobre las cuales descansaban los fundamentos y el mantenimiento del universo. Así mismo, se dice que TOT enseñó a los primeros egipcios los principios de la geometría y la agrimensura, la medicina y la botánica.. Según afirma la leyenda, fue el inventor de los números, de las letras del alfabeto y de las artes de leer y escribir. Era el gran Señor de la Magia, capaz de mover objetos con el poder de la voz, el autor de todas las obras sobre cada rama de la ciencia, tanto humana como divina. Arquímedes (287-212 a.C.), notable matemático e inventor griego, que escribió importantes obras sobre geometría plana y del espacio, aritmética y mecánica. Nació en Siracusa, Sicilia, y se educó en Alejandría, Egipto. En el campo de las matemáticas puras, se anticipó a muchos de los descubrimientos de la ciencia moderna, como el cálculo integral, con sus estudios de áreas y volúmenes de figuras sólidas curvadas y de áreas de figuras planas. Demostró también que el volumen de una esfera es dos tercios del volumen del cilindro que la circunscribe. En mecánica, Arquímedes definió la ley de la palanca y se le reconoce como el inventor de la polea compuesta. Durante su estancia en Egipto inventó el ‘tornillo sin fin’ para elevar el agua de nivel. Arquímedes es conocido sobre todo por el descubrimiento de la ley de la hidrostática, el llamado principio de Arquímedes, que establece que todo cuerpo sumergido en un fluido experimenta una pérdida de peso igual al peso del volumen del fluido que desaloja (véase Mecánica de fluidos). Se dice que este descubrimiento lo hizo mientras se bañaba, al comprobar cómo el agua se desplazaba y se desbordaba. Arquímedes pasó la mayor parte de su vida en Sicilia, en Siracusa y sus alrededores, dedicado a la investigación y los experimentos. Aunque no tuvo ningún cargo público, durante la conquista de Sicilia por los romanos se puso a disposición de las autoridades de la ciudad y muchos de sus instrumentos mecánicos se utilizaron en la defensa de Siracusa. Entre la maquinaria de guerra cuya invención se le atribuye está la catapulta y un sistema de espejos —quizá legendario— que incendiaba las embarcaciones enemigas al enfocarlas con los rayos del sol. Al ser conquistada Siracusa, durante la segunda Guerra Púnica, fue asesinado por un soldado romano que le encontró dibujando un diagrama matemático en la arena. Se cuenta que Arquímedes estaba tan absorto en las operaciones que ofendió al intruso al decirle: “No desordenes mis diagramas”. Todavía subsisten muchas de sus obras sobre matemáticas y mecánica, como el Tratado de los cuerpos flotantes, El arenario y Sobre la esfera y el cilindro. Todas ellas muestran el rigor y la imaginación de su pensamiento matemático Herón de Alejandría (c. 20-62 d.C.), matemático y científico griego. Su nombre también podría ser Hero (aproximadamente 18 escritores griegos se llamaron Hero o Herón, creándose cierta dificultad a la hora de su identificación). Herón de Alejandría nació probablemente en Egipto y realizó su trabajo en Alejandría (Egipto). Escribió al menos 13 obras sobre mecánica, matemáticas y física. Inventó varios instrumentos mecánicos, gran parte de ellos para uso práctico: la aelípila, una máquina a vapor giratoria; la fuente de Herón, un aparato neumático que produce un chorro vertical de agua por la presión del aire y la dioptra, un primitivo instrumento geodésico. Sin embargo, es conocido sobre todo como matemático tanto en el campo de la geometría como en el de la geodesia (una rama de las matemáticas que se encarga de la determinación del tamaño y configuración de la Tierra, y de la ubicación de áreas concretas de la misma). Herón trató los problemas de las mediciones terrestres con mucho más éxito que cualquier otro de su generación. También inventó un método de aproximación a las raíces cuadradas y cúbicas de números que no las tienen exactas. A Herón se le ha atribuido en algunas ocasiones el haber desarrollado la fórmula para hallar el área de un triángulo en función de sus lados, pero esta fórmula, probablemente, había sido desarrollada antes de su época LA INGENIERIA MECANICA EN LA EDAD MEDIA: EL RENACIMIENTO: LEONARDO DA VINCI. El humanismo del sigo XIV trajo consigo un deseo de renacimiento de la mentalidad clásica como reconocimiento a los grandes logros de los griegos y romanos en tiempos de antaño. Sin embargo, el espíritu humano hace a veces sus mayores progresos por los más extraviados caminos. Para conocer a aquellos griegos y romanos, admirables capitanes, estadistas y poetas, hacía falta desenterrar mármoles y descifrar manuscritos, aprender lenguas muertas y otras lenguas (en Florencia se estudiaba el griego como el verdadero camino de la salvación, como el principio de una nueva y esplendorosa Era, como la única manera de conseguir una vida civilizada), estudiar, investigar y comparar. Y he aquí el verdadero renacimiento: no de lo que renació (que no renació nada), sino de las facultades puestas en juego para hacer renacer, que se avivaron con aquel esfuerzo de la mente. Leonardo Da Vinci nació en 1452 en Vinci (Entre Florencia y Pisa). Arquitecto, pintor, escultor, Ingeniero y sabio italiano. Heredero de todas las aspiraciones artísticas del quattrocento florentino, aporta conclusiones geniales a la investigación de su siglo. A partir del siglo XVI, fue considerado como una especie de “mago”. A pesar de que muchas de sus obras se han perdido o no están acabadas, la significación de su obra es inmensa. Muere cerca de Amboise en el castillo de Cloux (propiedad de la madre de Francisco I) en 1519. Artista y hombre de ciencia italiano, hijo natural de un notario. Desde niño sintió ambición de querer abarcar toda disciplina humana; su padre presentó dibujos de Leonardo a Verrocchio, quien pasmado de las aptitudes que aquellos revelaban, aceptó en su taller al joven artista, que sin tregua llenaba cuadernos con croquis directos del natural y caricaturescos esbozos imaginativos de figuras y caras. Buscaba lo bello y lo feo, pretendiendo en todos los casos que perdurara la expresión fugitiva de los afectos anímicos y de las ideas. Colaboró en la pintura “ Bautismo de Cristo “ de Verrocchio y una de sus obras de la mocedad parece haber sido modelo de una tapicería, destinada al Rey de Portugal: “ Adán y Eva cogiendo la manzana”. Por los mismos tiempos hizo la “La Anunciación y La adoración de los Magos” de los Uffizi y el “San Jerónimo” del Vaticano. Poco favorecido por los Médicis, deja Florencia en 1482; invitado por Ludovico Esforza, llamado el Moro, se traslada a Milán como tañedor de lira, con rara lira en forma de cabeza de caballo, construida en plata y basándose en principios acústicos ignorados hasta entonces. En el certamen en que como tal se presenta, da respuestas muy agudas a diversas preguntas, causando la admiración de la Corte. Al poco tiempo es en Milán el ordenador de las fiestas de Ludovico y de aquellas que los magnates de la ciudad organizan en honor al Soberano; es también el ingeniero de los servicios hidráulicos, evidenciando con ello las aptitudes que expusiera en el memorial que al llegar a Milán presentó a su protector. Decía saber dirigir la construcción de puentes ligerísimos, fácil de poner y quitar, así como tener fácil manera de incendiar, en tiempo de guerra, los puentes del enemigo. Y añadía: “En tiempo de paz creo satisfacer perfectamente, tanto como el mejor, en arquitectura y composición de edificios públicos y privados, y en conducción de aguas de un lugar a otro; también puedo dedicarme a la escultura en mármol, en bronce o en barro, y a la pintura”. Para todo fue aprovechado en los diecisiete años que estuvo en Milán, con lo cual, si de una parte permitiéronle dar a conocer sus omnímodas cualidades, de otra le dificultaron concentrarse en trascendentales pinturas. Con todo, la etapa milanesa es un periodo de apogeo del arte de Leonardo, y ni la dirección de grandes trabajos hidráulicos, o los proyectos que hizo para el palacio de los Sforza y el tambor de la cúpula de la catedral, o los croquis de innumerables dispositivos militares, no le impidieron realizar dos de sus grandes creaciones pictóricas: “La Virgen de las Rocas, entregado hacia 1490, y el fresco del Cenáculo, terminado en 1497, en Santa María de las Gracias”. Al propio tiempo que en esta última obra, Leonardo trabaja en una gran escultura que en el memorial presentado a Ludovico el Moro se había ofrecido a realizar: la estatua ecuestre del fundador de la dinastía, Francisco Sforza. Con la caída de Ludovico empieza lo que se ha llamado la época errante de Leonardo, que comprende de 1500 a 1516. Así en marzo de 1500 está en Venecia, de donde pasa a Mantua para hacer el retrato de Isabel de Este; en Florencia al año siguiente, compone el cartón de Santa Ana para los servitas, esbozo para el cuadro que posee el Louvre; en 1502, entrado al servicio de César Borgia como ingeniero militar, inspecciona las fortalezas de Rimini, Pésaro, Cesena, Piombino y Siena; en 1503, con la caida del Borgia, vuelve a Florencia, donde retrata bellas damas: Ginebra de Vencí y Monna Lisa, tercera mujer del comerciante Giocondo, llamada por ello la Gioconda, en cuya efigie de medio cuerpo trabajó el pintor a lo largo de cuatro años. En 1507 viaja por la Lombardía; en 1510 está nuevamente en Florencia; dos años más tarde se halla en Milán y de allí parte a Roma, para vuelve a Milán donde conoce a Francisco I, quien apreciando su alto valor, se lo lleva consigo a Francia, donde reside el resto de su vida. Leonardo destacó por encima de sus contemporáneos como científico. Sus teorías en este sentido, de igual modo que sus innovaciones artísticas, se basan en una precisa observación y documentación. Comprendió, mejor que nadie en su siglo y aún en el siguiente, la importancia de la observación científica rigurosa. Desgraciadamente, del mismo modo que frecuentemente podía fracasar a la hora de rematar un proyecto artístico, nunca concluyó sus planificados tratados sobre diversas materias científicas, cuyas teorías nos han llegado a través de anotaciones manuscritas. Los descubrimientos de Leonardo no se difundieron en su época debido a que suponían un avance tan grande que los hacía indescifrables, hasta tal punto que, de haberse publicado, hubieran revolucionado la ciencia del siglo XVI. De hecho, Leonardo anticipa muchos descubrimientos de los tiempos modernos. En el campo de la anatomía estudió la circulación sanguínea y el funcionamiento del ojo. Realizó descubrimientos en meteorología y geología, conoció el efecto de la Luna sobre las mareas, anticipó las concepciones modernas sobre la formación de los continentes y conjeturó sobre el origen de las conchas fosilizadas. Por otro lado, es uno de los inventores de la hidráulica y probablemente descubrió el hidrómetro; su programa para la canalización de los ríos todavía posee valor práctico. Inventó un gran número de máquinas ingeniosas, entre ellas un traje de buzo, y especialmente sus máquinas voladoras, que, aunque sin aplicación práctica inmediata, establecieron algunos principios de la aerodinámica. Un creador en todas las ramas del arte, un descubridor en la mayoría de los campos de la ciencia, un innovador en el terreno tecnológico, Leonardo merece por ello, quizá más que ningún otro, el título de Homo universalis.INICIOS DE LA MECANICA CELESTE: KEPLER Y COPERNICO. El desarrollo de la mecánica celeste contribuiría posteriormente al desarrollo de la ingeniería mecánica, en cuanto al entendimiento del movimiento de los cuerpos en el espacio. Las “Tablas de Tolomeo” , síntesis de la ciencia antigua en astronomía, fueron aumentadas por los árabes y reeditadas por Alfonso el Sabio. Eran listas de posiciones de estrellas que servían para ubicar lugares donde se encontraban los viajeros. En cuanto a estrellas fijas, poco había que añadir a la compilación de Tolomeo; pero los planetas, con sus movimientos erráticos en la inmensidad del espacio, fueron un enigma para los astrónomos antiguos y continuaban siéndolo al terminar la Edad Media. La explicación no se podía elaborar mientras se persistiera en creer en el sistema planetario geocéntrico, es decir, con la Tierra en el centro; en cambio, el vagar de los planetas quedaba explicado con sólo hacer el mismo sistema planetario heliocéntrico, esto es, con el Sol en el centro. Tal simple enunciado es obra de Copérnico. Recientemente se ha comprobado que ya en la antigüedad Aristarco de Samos y Arquímedes sospecharon que el Sol era el centro del sistema planetario. En época de Copérnico, no se había inventado todavía los telescopios, por lo que observaba las estrellas a través de unas rendijas practicadas en las paredes de su casa. Convenientemente colocado dentro de la habitación, espiaba el tránsito o paso de cada estrella por el meridiano, al divisarla por la rendija. La altura, o ángulo sobre el horizonte, la medía con un simple cuadrante. Con estos primitivos y deficientes métodos de observación, invirtió Copérnico casi cuarenta años para observar lo que un astrónomo moderno, provisto de un telescopio ecuatorial, puede observar en una noche. Consignó sus observaciones y conclusiones en un libro que tituló “De Revolutionibus Orbium Coelestium”, el cual fue publicado cuando se hallaba en su lecho de muerte, en 1543. No vivió lo suficiente para ser testigo del caos que provocaría su teoría heliocéntrica.. Nicolás Copérnico, clérigo y matemático polaco, es considerado generalmente como el fundador de la astronomía moderna. Este honor le es atribuido porque fue el primero en llegar a la conclusión de que los planetas y el Sol no giraban alrededor de la Tierra. Copérnico lo propuso meramente como un modelo para calcular las posiciones de los planetas porque temía que la Iglesia le tachara de hereje si lo proponía como una auténtica descripción de la realidad. La ruptura de Copérnico marcó uno de los mayores cambios de paradigma que ha habido en la historia, abrió el camino a la astronomía moderna y afectó ampliamente a la ciencia, la filosofía y la razón. Antes que Copérnico, se creía que el Sol era otro planeta. Situar el Sol en el centro virtual del sistema planetario fue el punto de partida de la revolución copernicana. Al apartar la Tierra del centro del universo, donde se suponía que anclaba todos los cuerpos celestes, Copérnico se vió obligado a preguntarse por las teorías de la gravedad. Las explicaciones precopernicanas de la gravitación habían imaginado un único centro de gravedad (la Tierra), pero Copérnico arguyó que cada cuerpo celeste podría tener sus propias cualidades gravitacionales y sostuvo que, en cada uno de ellos, los objetos pesados tendían hacia su centro. Esta visión condujo finalmente a la teoría de gravitación universal, pero su impacto no fue inmediato. En 1543, Copérnico sufrió una parálisis del lado derecho y se fue debilitando física y mentalmente. El declarado perfeccionista que era no tuvo otra opción que abandonar el control de su manuscrito, De revolutionibus, en las últimas etapas de impresión. Confió el manuscrito a su alumno, Georg Rheticus, pero cuando éste se vio obligado a dejar Nuremberg, el manuscrito cayó en manos del Teólogo luterano Andreas Osiander. Éste, esperando apaciguar a los partidarios de la teoría egocéntrica, introdujo algunas alteraciones son el conocimiento y consentim,iento de Copérnico: introdujo la palabra “hipótesis” en la portada, borró párrafos importantes y añadió frases que diluían el impacto y la certeza de la obra. Se dice que Copérnico recibió un ejemplar de su libro impreso en Frauenburg, en su lecho de muerte, sin darse cuenta de las revisiones de Osiander. Sus ideas permanecieron en una relativa oscuridad durante casi cien años, pero el siglo XVII vio como gente de la talla de Galileo Galilei, Kepler e Isaac Newton construían teorías de universos heliocéntricos, apartando definitivamente ideas aristotélicas. Es Johann Wolfgang von Goethe, el gran escritor y científico alemán, quien más elocuentemente ha escrito sobre las contribuciones de Copérnico: “ De todas las opiniones y descubrimientos, ninguna debe haber ejercido mayor efecto sobre el espíritu humano que la doctrina copernicana. Apenas el mundo había sido considerado como redondo y completo en sí mismo, cuando se le pidió que renunciara al tremendo privilegio de ser el centro del universo. Quizá nunca se haya hecho una petición tan exigente a la humanidad, ya que, al admitirla, tantas cosas se desvanecían en humo y niebla. ¿Qué se hizo del Edén, nuestro mundo de inocencia, piedad y poesía? ¿Qué se hizo del testimonio de los sentidos, de las convicciones de una fe poético religiosa? No sorprende que sus contemporáneos rehusaran perder todo esto y presentaran toda la resistencia posible a una doctrina que autorizaba y exigía de sus conversos una libertad de miras y una grandeza de pensamiento desconocidas, ni tan siquiera soñadas, hasta entonces”. Quien continuó con la obra de Copérnico fue Johannes Kepler. Si alguna vez se otorgara un premio a la persona que a lo largo de la historia más se ha obstinado en la búsqueda de la precisión absoluta, éste podría obtenerlo el astrónomo alemán Johannes Kepler. Kepler estaba tan obsesionado por las mediciones que incluso calculó, con precisión de minutos, la duración de su propia gestación: 224 días, 9 horas y 53 minutos (había nacido prematuramente). No sorprende, pues, que en sus investigaciones astronómicas se esforzara en tan alto grado que llegó a dar las tablas astronómicas más exactas de su tiempo, conduciendo finalmente a la aceptación de la teoría centrada en el Sol del sistema planetario. Al igual que Copérnico, en cuyos trabajos se inspiró, Kepler era un hombre profundamente religioso. Consideraba sus incesantes estudios de las propiedades del Universo como un cumplimiento de su deber como cristiano de comprender el mundo que Dios había creado. Siendo estudiante, Kepler manifestó que sentía grandes deseos de “ examinar la naturaleza de los cielos, de las almas, de los genios; la esencia del fuego, el origen de las fuentes, el ascenso y descenso de las mareas, la forma de los continentes y de los mares”. Inició el estudio del número, las distancias y los movimientos de los cuerpos celestes, pero pronto recae en su incorregible imaginación y fantasía, observando que los planetas son sólo cinco, y como habían sido cinco los cuerpos geométricos regulares, era indudable que debía haber una razón divina, causa de esta igualdad y concordancia. El ordenador juicioso de la imaginación de Kepler fue el astrónomo danés Tycho Brahe, quien le decía “ No construyáis una cosmografía fundada en abstractas especulaciones, basadla en los sólidos cimientos de la observación y desde allí ascended gradualmente para averiguar las causas”. A diferencia de Copérnico, la vida de Kepler fue cualquier cosa menos tranquila y aburrida. Siempre escaso de dinero, recurría a menudo a la publicación de calendarios de astrología y de horóscopos que. Irónicamente, le hicieron ganar cierta celebridad local cuando sus predicciones se vieron confirmadas. Kepler también sufrió la muerte temprana de varios de sus hijos, así como la humillación de tener que defender en los tribunales a su excéntrica madre, Katherine, que tenía la reputación de ejercer la brujería y que estuvo a punto de ser quemada en la hoguera. Durante varios años, valiéndose de los instrumentos de la época, y con su terquedad para repetir observaciones, Tycho Brahe compiló en Uraniborg – Dinamarca, millares de datos que después sirvieron a Kepler para formular sus famosas leyes. A pesar de sus éxitos, Kepler nunca ganó ni prestigio ni mucho dinero, y en varias ocasiones se vio obligado a escapar de los países en que vivía, a causa de las revoluciones religiosas y las luchas civiles, de hecho, abandonó Linz en 1626 debido a la guerra de los Treinta años, que iniciada en 1618, diezmó las tierras austríacas y alemanas. Al final se estableció en la ciudad de Sagan, en Silesia. Allí intentó terminar lo que podríamos describir como una novela de ciencia ficción, en la que había jugueteado durante años, con ciertos perjuicios para su madre durante el juicio por brujería. “Sueño de la Luna” es un diálogo imaginario con un “ demonio” conocedor del Universo que explica al protagonista cómo podría viajar a la Luna y que fue descubierto y presentado como prueba durante el juicio contra Catherine. Kepler tuvo que dedicar muchas energías a defender que el trabajo era pura ficción y que el demonio que en él aparecía era un mero artificio literario. El libro es único, no sólo porque se avanzó en su tiempo en fantasía, sino también porque constituía una especie de tratado en apoyo de la teoría copernicana. Cuando murió en 1630, a los cincuenta y nueve años, mientras intentaba cobrar un sueldo retrasado, Kepler había descubierto tres leyes del movimiento planetario que aún hoy se enseñan a los estudiantes en la clases de física, mecánica y dinámica: Primera ley: Los planetas describen órbitas elípticas alrededor del Sol y éste se halla en un foco de las elipses. Segunda ley: Las líneas imaginarias que van del Sol a cada planeta recorren áreas iguales en el mismo tiempo. Tercera ley: El cuadrado del tiempo que emplea un planeta en girar alrededor del Sol es proporcional al cubo de su distancia media al Sol. Y fue la tercera ley de Kepler, y no una manzana, lo que condujo a Isaac Newton al descubrimiento de la ley de gravitación. Johannes Kepler fue un hombre enamorado del orden cósmico y la armonía estética, y todo lo que descubrió estuvo inextricablemente entrelazado con su visión de Dios. En su epitafio, que compuso él mismo, dice: “ Medí los cielos; ahora mediré las sombras de la Tierra. Mi alma era del cielo, pero la sombra de mi cuerpo reposa aquí”. LAS LEYES DEL MOVIMIENTO GALILEO E ISAAC NEWTON. En 1633, noventa años después de la muerte de Copérnico, el astrónomo y matemático italiano Galileo Galilei fue llevado a Roma para ser juzgado por herejía ante la inquisición. Los cargos procedían de la publicación de su libro Diálogo sobre los dos principales sistemas del mundo: ptolomaico y copernicano. En este libro, Galileo declaró enérgicamente, desafiando un edicto de 1616 contra la difusión de la doctrina copernicana, que el sistema heliocéntrico no era una simple hipótesis, sino que correspondía a la verdad. No hubo vacilaciones en el veredicto. Galileo admitió que quizá había ido demasiado lejos en sus argumentos a favor del sistema copernicano, a pesar de los avisos previos de las autoridades de la Iglesia católica romana. La mayoría de los cardenales del tribunal lo hallaron “vehementemente sospechoso de herejía” por apoyar y enseñar la idea de que la Tierra está en movimiento y no es el centro del universo, y lo condenaron a prisión perpetua. Galileo fue obligado a firmar una retractación manuscrita y a abjurar públicamente de sus creencias. De rodillas, y con las manos sobre la Biblia, pronunció su abjuración en latín. Se dice que Galileo, al levantarse susurró en voz baja “ Eppur si muove “ (“sin embargo se mueve”). Esta frase cautivó durante siglos a científicos y estudiosos, ya que representaba un desafío al oscurantismo y una noble determinación de buscar la verdad aún en las circunstancias más adversas. Corresponde plenamente al carácter de Galileo haber cedido sólo verbalmente a las exigencias de la Iglesia en su abjuración y haber vuelto después a sus estudios cinéticos, correspondieran o no a principios copernicanos. Galileo nació en Pisa en el año 1564. Empezó estudiando para médico en la Universidad Pisana, pero pronto su vocación por las matemáticas y la física le desvió de la medicina. Su primer descubrimiento, la ley del péndulo, lo realizó ciando sólo tenía diez y siete años. Estaba en la catedral de Pisa cuando vio que para encender una lámpara, la retiraban hacia un lado. Al dejar de retenerla, una vez encendida, la lámpara oscilaba como un péndulo, con movimientos que eran cada vez menores, pero de igual duración. A falta de cronómetro, Galileo midió el compás regular de las oscilaciones de la lámpara valiéndose de los latidos de su propio pulso. En el año 1586 realizó interesantes descubrimientos de hidrostática, que le dieron celebridad y pronto fue nombrado profesor de matemáticas de la Universidad de Pisa. Allí continuó sus estudios sobre la caída de los cuerpos. Galileo llegó a la conclusión de que la velocidad de un cuerpo al caer depende del tiempo que ha estado cayendo, esto es, que al empezar va despacio y aumenta su velocidad a cada unidad de tiempo, y que los espacios recorridos al caer son proporcionales a los cuadrados de los periodos de tiempo durante los cuales el cuerpo ha estado cayendo. Como se ve en la formulación de estos principios, Galileo podía formular la Ley de la Gravedad, aunque sin darle el carácter de Ley del Universo, que es lo que hace sublime la Ley de Gravitación Universal de Newton. Su obra más nombrada “Dos Nuevas Ciencias” representó una contribución tan grande a la física, que los estudiosos afirman que el libro se anticipó a las leyes del movimiento de Isaac Newton. Cuando fue publicado, sin embargo, Galileo había perdido la vista. Vivió los años restantes de su vida en Arcetri, donde murió el 8 de enero de 1642. Las contribuciones de Galileo a la humanidad nunca han sido subestimadas. Albert Einstein lo reconoció cuando escribió: “Las proposiciones obtenidas por métodos puramente lógicos son completamente vacías en lo que respecta a su relación con la realidad. Que Galileo lo advirtiera, y que particularmente lo anunciara al mundo científico, lo convierte en el padre de la física moderna, es decir, de la ciencia moderna”. En 1979, el papa Juan Pablo II reconoció que la Iglesia católica romana podría haberse equivocado al condenar a Galileo, y nombró una comisión específica para reabrir el caso. Cuatro años más tarde, la comisión concluyó que Galileo no debería haber sido condenado, y la iglesia publicó todos los documentos relevantes de su juicio. En 1992, el papa asumió las conclusiones de la comisión. Mientras el estudio de la estática se remonta al tiempo de los filósofos griegos, la primera contribución importante a la dinámica fue hecha por Galileo (1564-1642). Los experimentos de Galileo sobre cuerpos uniformemente acelerados condujeron a Newton ( 1642-1727) a formular sus leyes fundamentales del movimiento. El 5 de febrero de 1676, Isaac Newton escribió una carta a su más acérrimo enemigo, Robert Hooke, que contenía la frase: “ Si he logrado ver más lejos, ha sido porque he subido a hombros de gigantes”. Presentada a menudo como un homenaje a los descubrimientos científicos de sus predecesores Copérnico, Galileo y Kepler, esta frase se ha convertido en una de las más citadas en la historia de la ciencia. En efecto, Newton reconoció las contribuciones de aquellos hombres, algunas veces en público y otras en escritos privados. Pero en su carta a Hooke, Newton se refería a las teorías ópticas, especialmente al estudio de los fenómenos de las láminas finas, a los que Hooke y René Descartes habían aportado importantes contribuciones. Algunos estudiosos han interpretado la frase como un velado insulto a Hooke, cuya postura encorvada y su baja estatura le hacían bien diferente de un gigante, especialmente a los ojos de alguien tan rencoroso como Newton. Aún así, y a pesar de sus disputas, Newton parecía reconocer humildemente la valiosa investigación en óptica de Hooke y de Descartes, adoptando un tono conciliador al final de la carta. Isaac Newton es considerado el padre del estudio del cálculo infinitesimal, la mecánica y el movimiento planetario, y de la teoría de la luz y el color. Pero se aseguró un lugar en la historia al formular la fuerza de la gravitación y definir las leyes del movimiento y de la atracción en su obra cumbre “ Principios Matemáticos de la filosofía Natural” (Philosophiae Naturalis Principia Matemática), conocida generalmente como los Principia. En ella, fundió las contribuciones científicas de Copérnico, Galileo, Kepler y otros en una gran sinfonía dinámica. Los Principia, el primer libro de física teórica, es unánimemente considerado como la obra más importante de la historia de la ciencia y el fundamento científico de la moderna visión del mundo. Newton escribió los tres libros que forman los Principia en tan sólo dieciocho meses y, sorprendentemente, entre graves crisis emocionales como las debidas a su competición con Kooke. Su rencor llegó a tales extremos, que suprimió del libro todas las referencias a Hooke, aunque no podemos descartar que el odio hacia su colega hubiera sido una de las fuentes de inspiración de los Principia. La más ligera crítica de su libro, aunque fuera envuelta en abundantes elogios, sumía a Newton en sombríos ensimismamientos durante meses o años. Este rasgo de su carácter se reveló muy tempranamente en su vida, y muchos se han preguntado cuántas preguntas más podría haber contestado de no haberse obsesionado con rencillas personales. Otros han especulado, en cambio, que sus descubrimientos y éxitos científicos podrían deberse en parte a sus rencorosas obsesiones y que quizá no habrían sido posibles si hubiera sido menos arrogante. Tal como su periodo adulto, la niñez de Newton estuvo llena de violentas explosiones de rencor, no solamente contra supuestos enemigos, sino también contra amigos y familiares. También manifestó muy tempranamente el tipo de curiosidad que definiría los grandes éxitos de su vida, interesándose en modelos mecánicos y en dibujo arquitectónico. Newton pasó incontables horas construyendo relojes, cometas llameantes, relojes de sol y molinos en miniatura (movidos por ratoncitos), además de dibujar detallados esbozos de animales y barcos. A los cinco años asistió a las escuelas en Skillington y Stoke, pero fue considerado uno de los peores estudiantes, siendo calificado en los informes de los profesores como “distraído” y “vago”. A pesar de su curiosidad y su demostrada pasión por aprender, no consiguió aplicarse a las tareas escolares. Finalmente en su juventud, Newton pudo ingresar al Trinity College en la Universidad de Cambridge. En Trinity, Newton recibía una ayuda para pagar el coste de su educación a cambio de hacer diversos trabajos, como servir las mesas y limpiar habitaciones para la facultad. Pero en 1664 fue admitido como becario, lo que le garantizó apoyo económico y le permitió liberarse de las tareas domésticas. Cuando la universidad cerró a causa de la epidemia de fiebre bubónica en 1665, Newton se retiró a Lincolnshire. En los dieciocho meses que pasó en su casa durante la epidemia se dedicó por su cuenta a la mecánica y las matemáticas, y empezó a concentrarse en óptica y gravitación. Este “annus mirabilis” (año milagroso), como Newton lo llamó, fue uno de los periodos más productivos y fértiles de su vida. Es en esta época, cuenta la leyenda, que le cayó una manzana en la cabeza, despertándolo de una siesta bajo un árbol y espoleándole a definir las leyes de la gravitación. Por inverosímil que resulte la historia, el mismo Newton escribió que la caída de una manzana había ocasionado su irrupción en el estudio de la gravitación, y se cree que fe entonces cuando realizó sus experimentos con péndulos. “Estaba en la flor de mi vida de investigador-recordó Newton años después- y las matemáticas y la filosofía me apasionaban como nunca lo han hecho desde entonces”. A su regreso a Cambridge, Newton estudió la filosofía de Aristóteles y de Descartes, así como la ciencia de Thomas Hobbes y de Robert Boyle. Quedó cautivado por la mecánica de Copérnico y la astronomía de Galileo, además de la óptica de Kepler. Más o menos en esta época empezó sus experimentos con prismas sobre refracción y dispersión de la luz, posiblemente en su habitación de Trinity o en su casa, en Woolsthorpe. Un acontecimiento en la universidad ejerció una profunda influencia sobre el futuro de Newton, la llegada de Isaac Barrow, que había sido nombrado profesor Lucasiano de matemáticas. Barrow reconoció las extraordinarias aptitudes matemáticas de Newton, y cuando dimitió de su cátedra en 1669 para dedicarse a la teología recomendó como sucesor en la cátedra al joven Newton, de veintisiete años. Los primeros estudios de Newton como profesor Lucasiano se centraron en el campo de la óptica. Se propuso demostrar que la luz blanca está compuesta por una mezcla de varios tipos de luz, cada uno de los cuales produce un color diferente del espectro al ser refractada en un prisma. Su serie de experimentos elaborados y precisos para demostrar que la luz está compuesta por partículas diminutas despertaron la ira de científicos como Hooke, que afirmaba que la luz viajaba en ondas. Hooke retó a Newton a presentar más pruebas de sus excéntricas teorías ópticas. La manera de responder de Newton fue característica (una manera que no dejó ni cuando maduró): se retiró, se propuso humillar a Hooke siempre que pudiera, y rehusó publicar su libro, Optiks, hasta que éste muriera, cosa que ocurrió en 1703. Al principio, en su cargo de profesor Lucasiano, Newton había hecho grandes progresos en sus estudios de matemáticas puras, pero compartía su trabajo con muy pocos de sus colegas. Ya en 1666 había descubierto métodos generales de resolver problemas de curvatura (lo que denominó teorías de fluxiones y fluxiones inversas). Este descubrimiento provocó una agria disputa con los partidarios del matemático y filósofo alemán Gottfried Wilhelm Leibniz, que más de una década después publicó sus descubrimientos sobre cálculo diferencial e integral. Ambos investigadores llegaron aproximadamente a los mismos principios matemáticos, pero Leibniz publicó sus trabajos antes que Newton. Los partidarios de éste acusaban a Leibniz de haber visto los papeles del profesor Lucasiano unos años antes, y el apasionado debate entre las dos facciones, conocido como la disputa de la prioridad de cálculo, no concluyó hasta la muerte de Leibniz, en 1716. Los malignos ataques de Newton, que a menudo se ampliaban hasta tocar las teorías de Dios y el universo, así como las acusaciones de plagio, amargaron y empobrecieron a Leibniz. La mayoría de los historiadores de la ciencia creen que, de hecho, los dos llegaron independientemente a sus ideas, y que la discusión carecía de sentido. En un crucial encuentro en 1684, tres miembros de la Royal Society, Robert Hooke, Edmond Halley y Christopher Wren, el célebre arquitecto de la catedral de San Pablo en Londres, se enzarzaron en un acalorado debate sobre la relación del inverso de los cuadrados que regía el movimiento de los planetas. A comienzos de la década de 1670, las discusiones mantenidas en los cafés de Londres y otros cenáculos intelectuales sostenían que la gravedad emanaba del Sol en todas direcciones y disminuía con un ritmo inverso al cuadrado de la distancia, diluyéndose más y más a medida que aumentaba la superficie de la esfera. El encuentro de 1684 fue, en efecto, el nacimiento de los Principia. Hooke declaró que había deducido la ley de Kepler de las elipses a partir de la idea de que la gravedad era una fuerza de emanación, pero no desvelaría su deducción a Halley ni Wren hasta que estuviera a punto de hacerla pública. Furioso, Halley fue a Cambridge, contó a Newton las pretensiones de Hooke y le planteó el siguiente problema ¿Cuál sería la forma de la órbita de un planeta alrededor del Sol si fuera atraído hacia éste por una fuerza inversamente proporcional al cuadrado de la distancia?. La respuesta de Newton fue asombrosa: “Sería una elipse”, respondió inmediatamente, y contó a Halley que había resuelto el problema cuatro años antes, pero que había extraviado la demostración en su despacho. A petición de Halley, Newton pasó tres meses rehaciendo y mejorando la demostración. Entonces, en una explosión de energía sostenida durante dieciocho meses, durante los cuales se absorbía tanto en su trabajo que a menudo se olvidaba de comer, fue desarrollando estas ideas hasta que su presentación llenó tres volúmenes. Newton decisió titular su obra Philosophiae Naturalis Principia Matemática, en deliberado contraste con los Principia Philosophiae de Descartes. Los tres libros de los Principia de Newton proporcionaron el nexo entre las leyes de Kepler y el mundo físico. Halley reaccionó con estupefacción y entusiasmo ante los descubrimientos de Newton. Para Halley, el profesor Lucasiano había triunfado donde todos los demás habían fracasado, y financió personalmente la publicación de la voluminosa obra como una obra maestra y un regalo a la humanidad. Donde Galileo había mostrado que los objetos eran estirados hacia el centro de la Tierra, Newton consiguió demostrar que esta misma fuerza, la gravedad, afectaba las órbitas de los planetas. También estaba familiarizado con el trabajo de Galileo sobre el movimiento de proyectiles, y dijo que el movimiento de la órbita de la Luna alrededor de la tierra obedecía también a los mismos principios. Newton demostró que la gravedad explicaba y predecía los movimientos de la Luna, así como la subida y bajada de las mareas en la Tierra. El libro primero de los Principia abarca las tres leyes de Newton del movimiento: Primera ley: Todo cuerpo sigue en su estado de reposo o de movimiento uniforme rectilíneo, salvo que sea obligado a cambiar dicho estado por fuerzas aplicadas. Segunda ley: El cambio de movimiento es proporcional a la fuerza que actúa sobre el cuerpo; y tiene lugar en la dirección en que se aplica la fuerza. Tercera ley: A cada acción se le opone una reacción igual; a, las acciones mutuas entre dos cuerpos siempre son iguales, y dirigidas en sentidos opuestos. La primera y tercera leyes de Newton del movimiento se usaron ampliamente en estática para estudiar a los cuerpos en reposo y las fuerzas que actuaban sobre ellos. Estas dos leyes se emplean también en dinámica; de hecho son suficientes para el estudio del movimiento de los cuerpos cuando no hay aceleración. Pero cuando los cuerpos están acelerados, es necesario utilizar la segunda ley de Newton para relacionar el movimiento del cuerpo con las fuerzas que actúan sobre él. Isaac Newton murió en marzo de 1727, tras accesos de inflamación pulmonar y de gota. Tal como se había propuesto, no tuvo rival en el campo de la ciencia. Este hombre que no parece haber tenido relaciones sentimentales con ninguna mujer (algunos historiadores han especulado sobre sus posibles relaciones con hombres, como el filósofo natural suizo Nicolas Fatio de Duillier) no puede ser acusado, sin embargo, de falta de pasión por su trabajo. El poeta Alexander Pope, contemporáneo de Newton, expresó con gran elegancia el regalo del pensador a la humanidad: La naturaleza y sus leyes yacían en la noche: Dios dijo: “ Sea Newton” y todo se hizo luz. Pese a las mezquinas disputas y la innegable arrogancia que marcaron su vida, hacia su fin Isaac Newton fue considerablemente modesto al enjuiciar sus éxitos: “ No sé qué pareceré al mundo, pero tengo la impresión de haber sido tan sólo como un chiquillo, jugando en la costa, divirtiéndome en buscar aquí y allá un guijarro más liso o más hermoso que de ordinario, mientras el gran océano de la verdad yacía ante mí, completamente por descubrir”. LOS APORTES MATEMÁTICOS DEL SIGLO XVIII MARCAN EL RUMBO DE LA INGENIERIA MECANICA Y OTRAS INGENIERIAS: La productividad matemática en el siglo XVIII se concentró en el Cálculo y en sus aplicaciones a la Mecánica. La Astronomía continuó siendo una fuente muy importante para la investigación matemática. Los matemáticos más destacados de este siglo fueron el alemán Leibniz, los suizos Euler y los hermanos Bernoulli: Jacob y Johann, el italiano Lagrange y el francés d’Alembert. La actividad científica en el siglo XVIII, llamado el siglo de las luces, estuvo centrada fundamentalmente alrededor de las academias, de las cuales las más sobresalientes eran las de París, Berlín y San Petesburgo. Fue un periodo en el cual algunos de los países líderes de Europa estuvieron gobernados por los llamados “déspotas ilustres”: Federico el Grande en Alemania, Catalina la Grande en San Petesburgo y Luis XIV y Luis XV en Francia, los cuales se rodearon de importantes hombres de ciencia, quienes aportaron sus conocimientos en ciencias naturales y en matemáticas aplicadas para el desarrollo militar y de manufactura. Se dice, por ejemplo, que la excelencia de la armada francesa en dicho periodo se debió a la asesoría ofrecida por matemáticos en la construcción de barcos y fragatas. La segunda mitad del siglo XVIII permite a Francia una hegemonía en el plano científico sobre el resto de las naciones europeas. Durante este periodo se tiene el gran proyecto de publicar la Enciclopedia (un compendio de todos los conocimientos de la época), aparecen los trabajos de Lagrange racionalizando la Mecánica; de Lavoiser modernizando la Química y de Bufón sentando las bases de la biología Moderna. Se crean instituciones muy importantes como L’Ecole Polytechnique, L’Ecole Normale y el Institut de France, las cuales favorecieron el profesionalismo en el modo de hacer ciencia y el contacto y la comunicación entre científicos. Aunque Euler fue el matemático líder de este periodo, Francia produjo trabajos de gran originalidad, allí la Matemática fue concebida como la ciencia para perfeccionar la Teoría de Newton. LAS LEYES DE LA TERMODINÁMICA: LA MAQUINA DE VAPOR y LA REVOLUCION INDUSTRIAL. El cúmulo de sacudidas políticas y sociales del siglo XVIII y principios del XIX contribuyeron a transformar el mundo tanto o más que el invento de la máquina de vapor y otras invenciones prácticas. La independencia de las colonias inglesas en América, la Revolución Francesa y, sobre todo, las Guerras Napoleónicas, obligaron a buscar nuevas rutas para el comercio y fomentaron el progreso de las industrias. Casi todas las naciones se vieron obligadas a fabricar lo que antes importaban del extranjero; otras tuvieron que abrirse nuevos mercados para los productos que exportaban a naciones enemigas. Inglaterra, viéndose boicoteada en Europa por Napoleón, buscaba en Sudamérica, El Cabo y la India la salida para sus productos. El bloqueo inglés obligó a Francia a fabricar con remolacha el azúcar, que antes llegaba de las Antillas. Se empezó a emplear la achicoria como substituto del café. Aunque estas dificultades no tenían mucha importancia por ser artículos de lujo, eran síntomas que casi excusarían de explicar lo que pasó con los de primera necesidad: papel, vidrio, jabón, tejidos y metales. Cada nación forzó su industria a producir más y mejor de lo que antes fabricaba. Ni el determinismo político, ni el fatalismo económico de los sociólogos modernos que hacen historia con cifras de preciso y jornales, pueden explicar la fenomenal transformación de Europa a principios del siglo XIX. El invento más conspicuo de esta época es, sin duda, la máquina de vapor. Se ha llamado el siglo del vapor al siglo XIX; la electricidad no ha allegado todavía beneficios comparables a los que allegó el empleo del vapor. El efecto mecánico de la fuerza de expansión del vapor de agua había sido observado desde muy antiguo, pero no se había conseguido aprovechar para usos prácticos. El descubrimiento de la máquina de vapor se hizo gradualmente. En un principio sólo se pensó en utilizarlo para producir el vacío por la condensación del vapor dentro de un émbolo, de modo que la presión atmosférica le obligara a retroceder. En 1690 Denis Papin, con su famosa marmita, producía el vacío dentro de un recipiente que llenaba de vapor y después condensaba enfriándolo. Parece que Papin ya tuvo la idea de utilizar su aparato para producir fuerza motriz y emplearla en la propulsión de navíos. Pero los marineros de Munden, creyendo que la invención de Papin podía quitarles trabajo, destruyeron un barco de cuatro ruedas que había construido, y no sabemos de lo que hubiera resultado de su invención. En cambio, pocos años más tarde Savery consiguió elevar agua con una máquina fundamentada en el principio de la marmita de Papin. Después de hecho el vacío en el recipiente, el agua empujada por la presión atmosféricasubía para llenarlo. En 1717 Newcomen imaginó otro artificio, que ya fue un gran progreso respecto del de Savery: el vapor empujaba un émbolo, se condensaba y la presión de la atmósfera hacía caer el émbolo, produciéndose un movimiento balancín, que movía una palanca. Esta hacía subir y bajar el pistón de una bomba para elevar el agua. El cilindro del émbolo de la máquina de Newcomen quedaba abierto por un lado, y así el vapor servía para empujar en una dirección; para retroceder se contaba con el vacío que producía el vapor al condensarse. James Watt nació en 1736. Su padre era comerciante acomodado de Edimburgo, pero perdió su fortuna y tuvo que enviar el niño a Londres. Allí aprendió el oficio de fabricante de instrumentos de física, e hizo también descubrimientos de química. A su regreso, los maestros de Edimburgo no quisieron reconocer el aprendizaje que Watt había hecho en Londres. Por ello Watt tuvo que encontrar ocupación como reparador de aparatos en el gabinete de física de la Universidad y allí inventó la máquina de vapor, pues al componer una de las máquinas de elevar agua de Newcomen se le ocurrieron varias mejoras por las que pidió patente de invención. Consistían, esencialmente, en cerrar el émbolo por ambos lados, obligando al vapor a empujarlo en ambas direcciones. Así podía conseguir fuerzas mucho mayores que la de la presión atmosférica en el vacío. Otra gran invención de Watt fue la de un brazo articulado que podía transformar el simple movimiento de palanca de la máquina de Newcomen en movimiento giratorio. En realizad, la máquina de Watt era ya la máquina de vapor que hemos usado hasta nuestros días. Se perfeccionó con doble émbolo, se le añadió un condensador, se inventó la caldera tubular, se le dieron proporciones gigantescas; pero el principio siempre fue el descubierto por Watt. En 1775 Watt encontró un socio capitalista, Matew Boulton, y la sociedad Boulton and Watt, de Birmingham, tuvo el monopolio de la construcción de máquinas de vapor por medio siglo. Las máquinas de Watt funcionaban a la perfección; sin embargo, al principio se emplearon casi únicamente en las minas de carbón. Servían para extraerlo a la superficie, en lugar de hacerlo las mujeres y los niños con capazos, y para achicar el agua de las galerías inundadas. La famosa lámpara de Humphrey Dhabi, inventada en 1815, que disminuyó los riesgos del grisú, acabó de abaratar el carbón al hacer posible la explotación de minas que antes se consideraban peligrosas. Las primeras industrias en utilizar la máquina de vapor fueron las de hilados y tejidos. Estos inventos fomentaron el desarrollo rápido de la industria por toda Europa. En 1750 la metalurgia en toda Europa se hallaba en un estado tan primitivo como en la Edad Media. La pirita de hierro se beneficiaba en hornos pequeños con carbón vegetal y fuelles de mano. El primer adelanto en la fabricación de hierro fue la introducción de los fuelles movidos con las máquinas de vapor. El segundo, ya un gran invento, fue el pudelado, que consiste en inyectar aire a través del hierro fundido para que, absorbiendo oxígeno, se convierta en hierro maleable. Este método se empezó a usar en Inglaterra en 1783, y al año siguiente se emplearon ya rodillos en lugar de martillos para forjar. Con tales procedimientos los ingleses se pusieron a la cabeza de la metalurgia, que hasta entonces había monopolizado Francia y Suecia. Expuesta en cifras, la producción de hierro en la Gran Bretaña (que en 1750 era de 17.000 toneladas) en 1826 se elevó a 17 millones y en 1830 había más que duplicado la producción últimamente mencionada: 39 millones de toneladas. Estimulados por la competencia inglesa, los forjadores franceses aplicaron el pudelado y hasta fueron más allá, empleando hulla en lugar de carbón vegetal para la fundición. En 1841 los hermanos Scheider, del Greuzot, inventaron el martillo de vapor; después vinieron los hornos Siemens y demás inventos. La transformación de la industria, convertida de oficio manual y doméstico en trabajo en gran escala con máquinas de vapor, exigía la correspondiente expansión en el comercio. Los primeros ensayos para aplicar la máquina de vapor a los transportes se hicieron por la vía fluvial; hubo embarcaciones movidas por vapor antes, mucho antes de que se pensara utilizarlo para arrastrar vehículos sobre rieles. EL AUTOMÓVIL Y EL MOTOR DE COMBUSTIÓN INTERNA: El intento de obtener una fuerza motriz que sustituyera a los caballos se remonta al siglo XVII. El vapor parecía el sistema más prometedor, pero sólo se logró un cierto éxito a finales del siglo XVIII. El vehículo autopropulsado más antiguo que se conserva, un tractor de artillería de tres ruedas construido por el ingeniero francés Joseph Cugnot en 1771, era muy interesante, pero de utilidad limitada. Después, una serie de ingenieros franceses, estadounidenses y británicos —entre ellos William Murdoch, James Watt y William Symington— inventaron vehículos todavía menos prácticos. En 1789 el inventor estadounidense Oliver Evans obtuvo su primera patente por un carruaje de vapor, y en 1803 construyó el primer vehículo autopropulsado que circuló por las carreteras estadounidenses. En Europa, el ingeniero de minas británico Richard Trevithick construyó el primer carruaje de vapor en 1801, y en 1803 construyó el llamado London Carriage. Aunque este vehículo no se perfeccionó, siguieron produciéndose mejoras en la máquina de vapor y en los vehículos. Estos avances tuvieron lugar sobre todo en Gran Bretaña, donde el periodo de 1820 a 1840 fue la edad de oro de los vehículos de vapor para el transporte por carretera. Eran máquinas de diseño avanzado, construidas por ingenieros especializados como Gurney, Hancock o Macerone. Sin embargo, esa naciente industria de fabricación tuvo una vida muy breve. Los trabajadores que dependían del transporte con caballos para su subsistencia fomentaron unos peajes o cuotas más elevados para los vehículos de vapor. Esta circunstancia tenía una cierta justificación, ya que dichos vehículos eran pesados y desgastaban más las carreteras que los coches de caballos. Por otra parte, la llegada del ferrocarril significó un importante golpe para los fabricantes de vehículos de vapor. La restrictiva legislación de la Locomotive Act de 1865 supuso la restricción final a los vehículos de vapor de transporte por carretera en Gran Bretaña, y durante 30 años impidió prácticamente cualquier intento de desarrollar vehículos autopropulsados para el transporte por carretera. Esto hizo que el desarrollo del motor de combustión interna tuviera lugar en otros países como Francia, Alemania y Estados Unidos. Thomas Edison, el inventor estadounidense, escribió en 1901: “El vehículo de motor debería haber sido británico. Ustedes (los británicos) lo inventaron en la década de 1830. Sus carreteras son las mejores después de las francesas. Tienen ustedes cientos de ingenieros especializados, pero han perdido su industria por el mismo tipo de legislación y prejuicios estúpidos que les han atrasado en muchos aspectos de la electricidad”. Aunque el científico holandés Christiaan Huygens diseñó un motor de combustión interna en 1678, nunca llegó a construirse. El suizo Isaac de Rivaz construyó un carro automotor en 1805, y en 1863 Étienne Lenoir fabricó en París un vehículo que funcionaba con gas del alumbrado. Pero hasta mediados de la década de 1880 el motor de combustión interna no alcanzó un nivel que permitiera su utilización de forma eficaz en vehículos de carretera. En 1866, dos ingenieros alemanes, Eugen Langen y August Otto, desarrollaron un motor de gas, y en 1876 Otto construyó un motor de cuatro cilindros que constituyó la base de casi todos los motores posteriores de combustión interna. La importante unión de motor y vehículo se produjo en 1885 y 1887, cuando Karl Benz y luego Gottlieb Daimler introdujeron los primeros automóviles de gasolina eficaces. El vehículo de Benz era el mejor, con una gran diferencia, ya que estaba diseñado como un todo y empleaba las nuevas tecnologías de la industria de la bicicleta. El carruaje de Daimler no era más que un coche de caballos adaptado. Benz empezó a producir de forma limitada su vehículo de tres ruedas en 1888, con lo que nació la moderna industria del automóvil. Sin embargo, el motor de Daimler era revolucionario y significó un cambio radical en la industria del automóvil. De hecho, Daimler estaba más interesado en vender motores que vehículos, como fuente de potencia para diferentes usos. En esa misma época, en las décadas de 1870 y 1880, los inventores e ingenieros franceses como la familia Bollée, Léon Serpollet o el conde De Dion y sus ingenieros Bouton y Trépardoux construyeron excelentes vehículos de vapor. Un acontecimiento crucial en la historia de la industria automovilística fue la Exposición Universal de París de 1889, donde los ingenieros franceses René Panhard y Émile Levassor conocieron el motor de Daimler. En 1890 obtuvieron los derechos para fabricar dicho motor, pero no vieron un gran futuro en el automóvil y concedieron a la empresa Peugeot el derecho a emplear motores Daimler en vehículos autopropulsados. Puede considerarse que Peugeot fue el primer fabricante de automóviles en serie de todo el mundo, ya que construyó 5 coches en 1891 y 29 en 1892. En 1893, Benz se convirtió en un fabricante de vehículos en toda regla. Aquel año, la carrera París-Burdeos demostró la superioridad del motor Daimler sobre los automóviles de vapor, a pesar de que estos últimos estaban muy desarrollados. En Estados Unidos también trabajaban pioneros de la fabricación de automóviles. En 1891, John W. Lambert construyó el primer vehículo de gasolina de Estados Unidos. En 1895, los hermanos Charles y Frank Duryea crearon la primera empresa automovilística estadounidense, después de haber creado un prototipo en 1893. Elwood Haynes, Alexander Winton y Henry Ford también mostraron interés por este campo en la década de 1890. La demanda de automóviles creció sin cesar a lo largo de los últimos años del siglo XIX. El mayor fabricante europeo, Benz, afirmaba en 1900 haber producido un total de 2.500 vehículos, y el estadounidense Olds fabricó 400 desde mediados de 1899 hasta 1900. En Estados Unidos, George Baldwin Selden obtuvo en 1895 una patente que cubría la aplicación a un vehículo de un motor de combustión interna. La patente fue asignada a la empresa Electric Vehicle Company en 1899. Varias empresas importantes compraron licencias, pero otras, encabezadas por Henry Ford, se negaron a hacerlo. El proceso judicial se inició en 1903 y terminó en 1911 —un año antes de que expirara la patente— con un veredicto favorable a Ford. Con anterioridad, Harry Lawson había intentado sin éxito obtener un monopolio similar en Gran Bretaña para todos los automóviles de gasolina, al crear en 1895 el British Motor Syndicate para explotar las patentes de Daimler y otros. Sin embargo, una decisión judicial de 1901 acabó con las aspiraciones monopolistas de Lawson. Gran Bretaña centró sus investigaciones en los motores de combustión interna —en lugar del vapor o la electricidad— antes que Estados Unidos, debido en gran parte al ejemplo francés y a que la eliminación de las restricciones de patentes fue anterior a la estadounidense. En 1911, en las carreteras de Estados Unidos había más de 600.000 automóviles, bastantes más que en los países europeos, pero muchos estaban propulsados por vapor o electricidad. Aunque tardó en arrancar, la industria británica acortó distancias con la francesa después de 1909. Entre 1909 y 1913 la producción francesa creció un 30%, mientras que en Gran Bretaña aumentó un 200%. En 1913, la producción de automóviles y vehículos comerciales era de 34.000 anuales, frente a los 45.000 de Francia y los 23.000 de Alemania. Sin embargo, la producción total europea era menos de una cuarta parte de la estadounidense. La combinación de una renta per cápita mayor, unas técnicas eficaces de producción en serie y una población dispersa hizo que el mercado y la industria automovilística de Estados Unidos superara con rapidez a la del resto del mundo, lo que en 1914 representaba fundamentalmente Europa. En ese año, en Estados Unidos había un vehículo por cada 77 personas, en Gran Bretaña había uno por cada 165, en Francia uno por cada 318 y en Alemania uno por cada 950. Esto también significaba que Gran Bretaña era el mayor mercado europeo. La producción en serie no fue inventada por Henry Ford. En 1798 Eli Whitney introdujo la producción normalizada de mosquetes, y las fábricas de carne de Chicago habían introducido cadenas de producción en la década de 1860. En 1902, el automóvil Oldsmobile ya se fabricaba en serie. A partir de 1908, cuando se introdujo el modelo de Ford, Henry Ford empezó a combinar esos factores y reunió las enseñanzas de un siglo de forma espectacular. Entre 1913 y 1915 en la fábrica de Ford de Highland Park se combinaron la producción normalizada de piezas de precisión (que hacía que fueran intercambiables) y la fabricación en cadenas de montaje, que simplificaba las operaciones y las dividía en zonas de trabajo. La eficacia de la producción era tal que los precios de los automóviles bajaban sin cesar. Los automóviles salían de la cadena de montaje cada 10 segundos, con un ritmo anual de 2 millones. Esto hizo que Estados Unidos se motorizara de forma masiva en la década de 1920. Los fabricantes europeos aprendieron la lección, en especial el británico Morris, el francés Citroën, el alemán Opel, el italiano Fiat y, naturalmente, las fábricas de Ford situadas fuera de Estados Unidos. A pesar de todo, en la década de 1920 Estados Unidos y Canadá producían más del 90% de los automóviles fabricados en el mundo. La mayoría de estos vehículos se vendían en Norteamérica, pero las exportaciones suponían un 35% del mercado mundial de automóviles. La producción de vehículos fuera de Estados Unidos sobrevivió en gran medida porque General Motors, Ford y Chrysler establecieron plantas de fabricación en el extranjero, pero sobre todo porque los gobiernos europeos protegieron su industria automovilística de la competencia estadounidense mediante aranceles y cuotas. En 1932, los aranceles eran del 33,3% en el Reino Unido, del 25% en Alemania, entre el 45 y el 70% en Francia y entre el 18 y el 23% en Italia. En 1929 se fabricaron 4,8 millones de vehículos en Norteamérica, frente a 554.000 en Europa occidental. En el periodo de entreguerras se produjo una fuerte reducción en el número de fabricantes de automóviles en la mayoría de los principales países productores. En 1939, el sector estaba dominado en Estados Unidos por General Motors, que en la década anterior había superado a Ford gracias a una mejor comercialización. El único fabricante importante además de estas compañías era Chrysler. En Alemania, los líderes del mercado eran Opel —que General Motors había comprado en 1928—, Mercedes-Benz y Auto Union. En Francia el sector estaba dominado por Renault, Peugeot y Citroën (véase Louis Renault; Armand Peugeot; André Citroën). Sólo en Gran Bretaña había más fabricantes en 1939 que en 1929. Allí, Morris y Austin rivalizaban por el primer puesto, seguidos por Ford, Vauxhall (de General Motors), Standard y Rootes. Las principales marcas especializadas eran Jaguar, Rover y Rolls-Royce. En el periodo posterior a 1945 comenzó una importante expansión de la producción y prosiguió la racionalización, tendencias que continúan en la actualidad. En 1950, Europa representaba el 13,6% de la producción mundial, que ascendía a 8,2 millones de vehículos. El número de fabricantes tradicionales continuó en declive. En Estados Unidos, Studebaker, Packard y American Motors abandonaron el sector o fueron absorbidos. En el Reino Unido, los principales fabricantes de propiedad británica se fusionaron en la década de 1960 para formar British Leyland, que cambió su nombre a Rover en 1986 y fue adquirida por BMW en 1994. En Francia, en la década de 1970, Peugeot compró Citroën y las instalaciones europeas de Chrysler en Gran Bretaña, Francia y España. Salvo algunas fábricas pequeñas, toda la industria automovilística italiana es propiedad de Fiat. En España, SEAT, que estaba a la cabeza del sector automovilístico español, empezó a notar la crisis en 1976 y ya a partir de 1984 inició un plan de colaboración con la alemana Volkswagen, que en 1986 adquirió el 51% de la empresa. Este proceso de reducción de empresas afectó a los coches, los vehículos comerciales y la fabricación de piezas. Aunque la fabricación de vehículos está dominada principalmente por empresas con enormes mercados oligopolistas y muy competitivos, es posible entrar en algún segmento de estos mercados (véase Oligopolio). A partir de 1960 tuvo lugar el surgimiento de la industria automovilística japonesa, que en ese año fabricó sólo 165.094 coches y en 1990 produjo 9.947.972. A mediados de la década de 1990, la industria automovilística surcoreana parecía constituir una fuerza importante, y en el futuro podría haber industrias locales importantes en India, China y Rusia. El crecimiento económico de Europa y la mayor eficiencia en la producción de vehículos hicieron que, a principios de la década de 1970, el consumo y producción total de automóviles en Europa superaran a los de Norteamérica por primera vez desde los primeros días de la industria. Los aranceles experimentaron grandes reducciones en todo el mundo desde principios de la década de 1960; la inadaptación de los coches estadounidenses para la mayoría de los mercados de exportación hizo que los primeros en beneficiarse fueran los fabricantes europeos y posteriormente los japoneses. Sin embargo, alrededor del 20% de la producción y venta de automóviles en Europa correspondía a fabricantes estadounidenses. En 1995 había en el mundo más de 625 millones de coches y vehículos comerciales en uso. De ellos, 193 millones correspondían a Estados Unidos, 17 millones a Canadá, 63 millones a Japón y 183 millones a Europa occidental. Si sólo se cuentan los coches, Europa occidental, con 162 millones, superaba a Estados Unidos, con 146 millones. Sin embargo, la combinación de un mayor poder adquisitivo per cápita y unos precios más bajos hacía que la densidad de automóviles fuera mayor en Estados Unidos que en Europa y el resto del mundo. En Estados Unidos hay 1,7 personas por automóvil, frente a 2,3 en Europa occidental. Las cifras de Europa oriental van desde 3,8 personas por automóvil en la República Checa hasta 16,0 en la antigua Unión Soviética. A título comparativo, en Japón hay 3,0 personas por automóvil, en Canadá 2,0 y en Australia 2,2 LA AVIACIÓN: El primer vuelo con éxito fue precedido de siglos de sueños, estudio, especulación y experimentación. Existían viejas leyendas con numerosas referencias a la posibilidad de movimiento a través del aire. Ciertos sabios antiguos creían que para volar sería necesario imitar el movimiento de las alas de los pájaros o el empleo de un medio como el humo u otro más ligero que el aire. Hacia el siglo V de nuestra era se diseñó el primer aparato volador: la cometa o papalote. En el siglo XIII el monje inglés Roger Bacon, tras años de estudio, llegó a la conclusión de que el aire podría soportar un ingenio de la misma manera que el agua soporta un barco. A comienzos del siglo XVI Leonardo da Vinci analizó el vuelo de los pájaros y anticipó varios diseños que después resultaron realizables. Entre sus importantes contribuciones al desarrollo de la aviación se encuentra el tornillo aéreo o hélice y el paracaídas. Concibió tres tipos diferentes de ingenios más pesados que el aire: el ornitóptero, máquina con alas como las de un pájaro que se podían mover mecánicamente; el helicóptero diseñado para elevarse mediante el giro de un rotor situado en el eje vertical, y el planeador en el que el piloto se sujetaba a una estructura rígida a la que iban fijadas las alas diseñadas a imagen de las grandes aves. Leonardo creía que la fuerza muscular del hombre podría permitir el vuelo de sus diseños. La experiencia demostró que eso no era posible. Fue una figura muy importante porque aplicó por primera vez técnicas científicas para desarrollar sus ideas. El desarrollo práctico de la aviación siguió varios caminos durante el siglo XIX. El ingeniero aeronáutico e inventor británico George Cayley, teórico futurista, comprobó sus ideas experimentando con cometas y planeadores capaces de transportar un ser humano. Diseñó un aparato en forma de helicóptero, pero propulsado por una hélice en el eje horizontal. Sus méritos le llevaron a ser conocido por sus compatriotas como el padre de la aviación. El científico británico Francis Herbert Wenham utilizó en sus estudios el túnel aerodinámico, sirviéndose del flujo del viento forzado en su interior para analizar el uso y comportamiento de varias alas colocadas una encima de otra. Fue además miembro fundador de la Real Sociedad Aeronáutica de Gran Bretaña. Otros personajes interesantes del mundo aeronáutico de la época fueron el inventor británico John Stringfellow y William Samuel Henson, quienes colaboraron a principios de la década de 1840, para fabricar el prototipo de un avión que pudiera transportar pasajeros. El aparato desarrollado por Stringfellow en 1848 iba propulsado por un motor de vapor y arrastrado por un cable, y consiguió despegar, aunque no pudo elevarse. El inventor francés Alphonse Penaud fabricó un modelo que se lanzaba con la mano e iba propulsado por bandas de goma retorcidas previamente, y consiguió en el año 1871 que volase unos 35 metros. Otro inventor francés, Victor Tatin, diseñó un ingenio propulsado por aire comprimido y equipado con un rudimentario tren de aterrizaje de cuatro ruedas. Lo sujetó a un poste central y las dos hélices consiguieron elevar el aparato en vuelos cortos y de baja altura. El inventor británico, nacido en Australia, Lawrence Hargrave desarrolló un modelo de alas rígidas que iba impulsado por paletas batientes movidas por un motor de aire comprimido. Voló 95 m en 1891. El astrónomo estadounidense Samuel Pierpont Langley fabricó en 1896 un monoplano en tándem impulsado por un motor de vapor cuyas alas tenían una envergadura de 4,6 m. El aeroplano hizo varios vuelos, recorriendo entre 900 y 1.200 m de distancia durante un minuto y medio. Subía en grandes círculos; luego, al pararse el motor, descendía lentamente para posarse en las aguas del río Potomac. Se hicieron numerosos esfuerzos para imitar el vuelo de las aves con experimentos basados en paletas o alas movidas por los músculos humanos, pero nadie lo logró. Merecen citarse el austriaco Jacob Degen entre 1806 y 1813, el belga Vincent DeGroof, que se estrelló y murió en 1874, y el estadounidense R. J. Spaulding, que patentó su idea del vuelo empujado por músculos en 1889. Más éxito tuvieron quienes se dedicaron al estudio de los planeadores y contribuyeron al diseño de las alas, como el francés Jean Marie Le Bris, quien probó un planeador con las alas batientes, el estadounidense John Joseph Montgomery y el renombrado alemán Otto Lilienthal. Este último realizó sus experimentos con cometas y ornitópteros, pero los mayores éxitos los obtuvo con sus vuelos en planeador entre 1894 y 1896. Por desgracia, murió en 1896 al perder el control de su aparato y estrellarse contra el suelo desde 20 m de altura. Percy S. Pilcher, de Escocia, que también había obtenido grandes éxitos con su planeador, tuvo asimismo un accidente mortal en 1899. El ingeniero estadounidense Octave Chanute consiguió en 1896 pequeños logros con sus planeadores de alas múltiples, pero su contribución más notable a la aviación fue un libro escrito en 1894 sobre los avances aeronáuticos. Los numerosos experimentos realizados con cometas durante esta época, consiguieron mejorar de forma notable los conocimientos sobre aerodinámica y estabilidad de vuelo. El inventor estadounidense James Means publicó sus resultados en los Aeronautical Annuals (Anuarios aeronáuticos) de 1895, 1896 y 1897. Lawrence Hargrave inventó en 1893 la cometa en forma de caja y Alexander Graham Bell desarrolló entre 1895 y 1910 diversas cometas en forma de tetraedro capaces de transportar a un ser humano en un pequeño alojamiento. Entre 1890 y 1901 se realizaron numerosos experimentos con prototipos provistos de motor. El más importante fue el de Langley, un aeroplano a un cuarto de escala de su tamaño real, que probó e hizo volar sin piloto en 1901 y 1903. Le llamó Aerodrome y fue la primera aeronave más pesada que el aire provista de un motor de gasolina que consiguió volar. El modelo a escala real se terminó en 1903 y realizó dos pruebas que acabaron en desgraciados accidentes. El aviador alemán Karl Jatho intentó en 1903, también sin éxito, volar un modelo motorizado de tamaño real. Los logros conseguidos a lo largo del siglo XIX aportaron los fundamentos necesarios para el éxito de los hermanos Wright, pero los mayores avances se debieron a los esfuerzos de Chanute, Lilienthal y Langley a partir de 1885. En 1903 aún no se habían conseguido la estabilidad y el control necesarios para un vuelo prolongado, pero los conocimientos aerodinámicos, y sobre todo el éxito de los motores de gasolina, que sustituyeron a los más pesados de vapor, permitirían que la aviación evolucionara con rapidez. El día 17 de diciembre de 1903, cerca de Kitty Hawk, en el estado de Carolina del Norte, los hermanos estadounidenses Wilbur y Orville Wright realizaron el primer vuelo pilotado de una aeronave más pesada que el aire propulsada por motor. El avión fue diseñado, construido y pilotado por ambos hermanos, quienes realizaron dos vuelos cada uno. El más largo fue el de Wilbur con 260 m recorridos en 59 segundos. Al año siguiente continuaron mejorando el diseño del avión y su experiencia como pilotos a lo largo de 105 vuelos, algunos de más de 5 minutos. En 1905 llegaron a recorrer 38,9 km en 38 minutos y 3 segundos. Todos los vuelos se realizaron en campo abierto, regresando casi siempre cerca del punto de despegue. Hasta 1906 nadie más consiguió volar en un avión. En ese año el húngaro residente en París, Trajan Vuia, realizó algunos saltos muy cortos y también lo consiguió Jacob Christian Ellehammer en Dinamarca. El primer vuelo oficialmente registrado en Europa lo hizo en Francia el brasileño Alberto Santos Dumont, y su trayecto más largo lo logró el 12 de noviembre de 1906 cubriendo una distancia de 220 m en 22,5 segundos. El aeroplano, registrado como 14-bis, había sido diseñado por él y construido en la primera fábrica de aviones del mundo, la de los hermanos Voisin en París. Era como una gran cometa en forma de caja en la parte trasera y otra pequeña en la delantera, unidas por la estructura cubierta de tela. El motor era un Levavasseur Antoinette de 40 CV y estaba ubicado, junto con la hélice, en la parte posterior. El piloto iba de pie en una cesta situada delante del ala principal. En Europa nadie consiguió volar más de un minuto hasta finales de 1907, cuando lo logró Henri Farman en un avión construido también por Voisin. En contraste con Europa, los hermanos Wright conseguían en Estados Unidos superar sus marcas día a día. El 3 de septiembre de 1908, Orville Wright hizo una demostración con un modelo más veloz para el Cuerpo de Señales del Ejército en Fort Meyer, Virginia. El 9 de septiembre completó el primer vuelo mundial de más de una hora y, también por primera vez, se transportó un pasajero, el teniente Frank P. Lamh, durante 6 minutos y 24 segundos. Estas demostraciones se interrumpieron el 17 de septiembre a causa de un accidente en el que resultaron heridos Orville y su pasajero, el teniente Thomas E. Selfridge, quien murió horas después a consecuencia de una conmoción cerebral. Fue la primera persona muerta en accidente de avión propulsado por motor. Entretanto Wilbur Wright, que había ido a Francia en agosto, completó, el 31 de diciembre, un vuelo de 2 horas y 20 minutos demostrando un control total de su avión con suaves virajes, subidas y descensos a su entera voluntad. Recuperado de sus heridas y con la colaboración de Wilbur, Orville reanudó las demostraciones para el Cuerpo de Señales en julio de 1909 y cumplió sus requisitos a finales de mes. El aeroplano fue comprado el 2 de agosto y se convirtió en el primer avión militar operativo de la historia. Permaneció en servicio activo durante dos años y después fue retirado y trasladado al Instituto Smithsonian, en la ciudad de Washington, donde puede contemplarse todavía. Una figura importante entre los diseñadores, fabricantes y pilotos estadounidenses fue Glenn Hammond Curtiss, de Hammondsport, Nueva York. En 1907 realizó en solitario un vuelo en el dirigible construido por Thomas Baldwin, propulsado por un motor de motocicleta de la fábrica de Curtiss que él mismo había modificado. En mayo del año siguiente Curtiss voló, también en solitario, el aeroplano diseñado y fabricado por un grupo conocido como la Asociación de Experimentos Aéreos, organizada por Alexander Graham Bell. Curtiss era uno de sus cinco miembros. Con su tercer avión, el June Bug, el 4 de julio de 1908 Curtiss cubrió la distancia de 1.552 m en 42,5 segundos y ganó el Trofeo Científico Americano, primer premio estadounidense concedido al vuelo de un avión. En Reims, Francia, el 28 de agosto del año siguiente, Curtiss ganó el primer torneo internacional de velocidad, al conseguir una marca de 75,6 km/h. El 29 de mayo de 1910 ganó también el Premio New York World, dotado con 10.000 dólares, por realizar el trayecto desde Albany, en el estado de Nueva York, hasta la ciudad de Nueva York, y en agosto completó el trayecto desde Cleveland a Sandusky, Ohio, sobrevolando la costa del lago Erie. En enero de 1911 consiguió ser el primer estadounidense en desarrollar y volar un hidroavión. En Europa lo había conseguido el 28 de marzo de 1910 el francés Henri Fabre. El pionero en cruzar el canal de la Mancha fue el ingeniero y piloto francés Louis Blériot. El día 25 de julio de 1909, durante 35,5 minutos recorrió 37 km, desde Calais, Francia, hasta Dover, Inglaterra, en un avión monoplano diseñado y fabricado por él mismo. Durante los años posteriores a la I Guerra Mundial se realizaron grandes progresos tanto en el diseño de los aeroplanos como en los motores. Los aviones de dos alas con los motores y las hélices situadas en la parte posterior pronto fueron sustituidos por aviones con los motores situados en la parte delantera. Había muy pocos modelos de monoplanos, pero, en cambio, durante la guerra ambos contendientes fabricaron enormes biplanos con dos, tres y hasta cuatro motores, que en Europa fueron al principio del tipo rotativo, aunque pronto se sustituyeron por los modelos radiales. En Gran Bretaña y Estados Unidos predominaron los motores refrigerados por agua. El transporte aéreo de correo se aprobó oficialmente en Estados Unidos en el año 1911 y se realizó el primer vuelo el 23 de septiembre. El piloto, Earle Ovington, llevó la saca de correos en sus rodillas en un vuelo que tan sólo duró 5 minutos y recorrió los 8 km que hay entre el bulevar Nassau y Mineola, ambos en Long Island, Nueva York. Ovington lanzó la saca sobre Mineola, donde fue recogida y trasladada a la oficina de correos. El servicio duró sólo una semana (véase Correo aéreo). En 1911 se completó el primer vuelo transcontinental en Estados Unidos, desde la ciudad de Nueva York hasta Long Beach en California. Lo consiguió el piloto estadounidense Calbraith P. Rodgers. Salió de Sheepshead Bay, en Brooklyn, Nueva York, el 17 de septiembre, al mando de un aeroplano Wright, y aterrizó en su destino el 10 de diciembre, 84 días más tarde. El tiempo real de vuelo fue de 3 días, 10 horas y 14 minutos. Durante la I Guerra Mundial se usaron como armas tanto los aeroplanos como las aeronaves más ligeras que el aire. Las urgentes necesidades de la guerra estimularon a los diseñadores para construir modelos especiales para reconocimiento, ataque y bombardeo. Como consecuencia de la presión de la guerra fueron entrenados más pilotos y construidos más aviones en los 4 años de conflicto que en los 13 años transcurridos desde el primer vuelo. Gran parte de los excedentes militares vendidos después de la guerra fueron adquiridos por aviadores formados y entrenados durante la misma, dispuestos a realizar con ellos cualquier actividad que les produjera ingresos económicos: transporte de pasajeros, fotografía aérea, propaganda (por lo general, escribiendo los nombres de los productos en sus aviones), vuelos de instrucción, carreras aéreas y exhibiciones acrobáticas. Los vuelos transoceánicos comenzaron con el NC-4. El vuelo de este enorme hidroavión se inició en Rockaway Beach, Long Island, el 8 de mayo de 1919 y finalizó el 31 en Plymouth, Inglaterra, tras varias escalas intermedias en Terranova (Canadá), las islas Azores y Lisboa (Portugal). El primer vuelo transatlántico sin escalas lo consiguieron los pilotos británicos John William Alcock y Arthur Whitten Brown. Entre el 14 y el 15 de junio de 1919, en poco más de 16 horas, volaron desde Saint John's, Terranova, hasta Clifden, Irlanda, y ganaron un premio de 50.000 dólares otorgado por el London Daily Mail. El día 26 de enero de 1926 se inició en Palos de Moguer, España, el vuelo del Plus Ultra. Era un hidroavión Dornier Wall con el que el piloto español comandante Ramón Franco y su tripulación, tras varias escalas y algún incidente, consiguieron llegar el 7 de febrero a Buenos Aires, Argentina. Entre el 20 y el 21 de mayo de 1927 se completó el primer vuelo en solitario cruzando el océano Atlántico. Lo llevó a cabo el aviador estadounidense Charles A. Lindbergh desde la ciudad de Nueva York hasta París, recorriendo una distancia de 5.810 km en 33,5 horas. Lindbergh se convirtió con esta hazaña en uno de los pilotos más famosos de la historia de la aviación. Pero nadie había conseguido cruzar el Atlántico sin escalas en dirección oeste, a causa de los vientos contrarios, hasta que entre el 12 y el 13 de abril de 1928 el capitán alemán Hermann Köhl, el barón de la misma nacionalidad Gunther von Hünefeld y el capitán irlandés James Fitzmaurice, tras salir de Dublín, Irlanda, volaron 3.564 km, hasta Greenly Island, Labrador. Existía entonces una auténtica fiebre por ser los pioneros en realizar cualquier trayecto, y así los australianos Charles Kingsford-Smith y Charles T. P. Ulm, junto con los estadounidenses Harry W. Lyon y James Warner, emprendieron la Southern Cross y volaron desde Oakland, California, hasta Sydney, Australia, con un total de 11.910 km y escalas en Hawai, islas Fiji y Brisbane, Australia. Tres pilotos estadounidenses, Amelia Earhart, Wilmer Stultz y Louis Gordon, cruzaron el Atlántico entre Trepassey Bay, Terranova, y Burry Port, Gales, el día 17 de junio y del 3 al 5 de julio. El capitán Arturo Ferrarin y el comandante Carlo P. Del Prete, pilotos del Ejército italiano, realizaron un vuelo de 7.186 km sin escalas desde Roma hasta Genipabu, Brasil. En el año 1920 se crearon las primeras líneas aéreas para correo y pasajeros entre Cayo Hueso, Florida, y La Habana, Cuba, así como entre Seattle, Washington (Estados Unidos), y Vancouver, Columbia Británica (Canadá). En 1921 se estableció el servicio transcontinental regular de correo entre las ciudades de Nueva York y San Francisco, inaugurado por el departamento del Servicio Postal. En 1925 el Congreso aprobó el decreto Kelly sobre correo aéreo, que autorizaba al servicio postal a realizar contratos con los operadores de transporte aéreo para trasladar el correo por avión. Ya en 1926 se inauguraron catorce líneas aéreas nacionales y se establecieron enlaces entre Estados Unidos, América Central, América del Sur y Canadá. Entre 1930 y 1940 el transporte aéreo creció rápidamente y se acometieron frecuentes vuelos transoceánicos y de larga distancia. Los aviadores estadounidenses, volando pequeños aviones, redujeron cada vez más las plusmarcas de tiempo en los vuelos transcontinentales sin escalas y posteriormente las mejoraron con aviones de transporte. En 1930 Roscoe Turner voló desde Nueva York hasta Los Ángeles en 18 horas y 43 minutos; Frank Hawks lo hizo en sentido inverso en seis horas menos. En 1937 Howard Hughes invirtió sólo 7 horas y 28 minutos entre Burbank, California, y Newark, Nueva Jersey, y en 1939 Ben Kelsey tardó 17 minutos más entre California y Nueva York. La más grande de las compañías internacionales que operaban en el momento de comenzar la II Guerra Mundial era Pan American Airways. Junto con sus empresas subsidiarias y afiliadas servía una red de 82.000 millas en rutas que llegaban a 47 países y colonias en todos los continentes. Las exigencias de la guerra aceleraron el desarrollo de los aviones y se consiguieron importantes avances en los de bombardeo y combate, así como en el transporte aéreo de tropas paracaidistas, tanques y equipo pesado. De esta forma y por primera vez en la historia, la aviación se convirtió en el factor más decisivo en el desarrollo de la guerra. También se extendió con rapidez la fabricación de pequeños aviones. Bajo la supervisión del programa de entrenamiento de pilotos civiles, patrocinado por la Administración Civil Aeronáutica de Estados Unidos, los operadores privados dieron grandes facilidades para la formación como pilotos de miles de estudiantes que se convirtieron así en la columna vertebral de las fuerzas aerotransportadas de los tres ejércitos. Los aviones diseñados para uso privado encontraron también un amplio uso militar en todo el mundo, por lo que en 1941 el Ejército y la Armada de Estados Unidos compraron grandes cantidades de aviones ligeros que dedicarían a diversas misiones militares. En 1941 la aviación militar estadounidense operaba en todos los frentes. La industria aeronáutica tenía empleadas a 450.000 personas frente a las 190.000 que había antes de la guerra. Ese año, 3.375.000 pasajeros fueron transportados por las 18 compañías aéreas estadounidenses, un millón más que en 1940. La carga de pago y el correo se incrementaron en cerca de un 30 por ciento. Hacia el final de la guerra las batallas aéreas crecieron en intensidad y extensión y la producción de aviones alcanzó un máximo. Por otra parte, las líneas aéreas nacionales también establecieron nuevas plusmarcas tanto en el transporte de pasaje como de carga. Como consecuencia de todo ello, el número de aviones producidos en Estados Unidos en 1944 alcanzó la importante cifra de 97.694, con una media de 4.770 kg por avión. En el mismo año, Alemania ponía en combate dos ingenios completamente nuevos en el mundo de la aviación: el primer avión reactor y el primer proyectil volante. En 1945 la producción de aeroplanos militares en Estados Unidos se redujo drásticamente, pero los pedidos de aviones civiles se incrementaron de forma considerable. Al finalizar el año, los fabricantes tenían contratos para construir 40.000 aviones, en contraste con la producción máxima de 1941, que fue de 6.844. De nuevo las líneas aéreas nacionales e internacionales estadounidenses rompieron las plusmarcas anteriores en todos los tipos de tráfico y consiguieron sustanciales mejoras con respecto a 1941. Se redujeron las tarifas tanto de pasaje como de carga, y en 1945 volvieron a operar todos los servicios comerciales internacionales. La experiencia obtenida en la fabricación de aviones militares durante la guerra fue utilizada en la construcción de aviones civiles nada más terminar las hostilidades. Las compañías aéreas dispusieron de aviones más grandes y mas rápidos con adelantos como las cabinas presurizadas. Se mejoraron los aeropuertos, los pronósticos meteorológicos y las ayudas a la navegación fueron más eficientes y aumentó la demanda pública de transporte aéreo de pasaje y carga, que creció a niveles desconocidos hasta entonces gracias a la repentina prosperidad de la posguerra. Los experimentos en el campo del diseño aerodinámico, de los nuevos metales, nuevas plantas de potencia y avances electrónicos trajeron el desarrollo de los aviones turborreactores de alta velocidad, diseñados para vuelos transoceánicos, vuelos supersónicos, aviones cohete experimentales, aviones de despegue corto o vertical (STOL, VTOL) y cohetes espaciales (véase Avión; Propulsión a chorro; Astronáutica). En diciembre de 1986 el avión ligero experimental Voyager completó con éxito el primer vuelo alrededor del mundo sin escalas y sin repostar. Fue diseñado por Burt Rutan, que lo dotó de líneas muy poco ortodoxas que recuerdan en algunos aspectos a un catamarán. El avión iba provisto de dos motores, el delantero para despegar, maniobrar y aterrizar y el posterior para el vuelo de crucero. Los materiales eran de plástico ligero por lo que su peso al despegar era tan sólo de 4.420 kg y cargaba 4.500 l de combustible distribuidos en 17 depósitos. Una vez consumidos, su peso al aterrizar era de 840 kg. Los pilotos fueron Dick Rutan (hermano de Burt) y Jeanna Yeager, y volaron 40.254 km en 9 días, 3 minutos y 44 segundos, a una velocidad media de 186,3 km/h. Este vuelo estableció una nueva plusmarca de distancia y tiempo en el aire, duplicando la de distancia, que permanecía desde 1962 en 20.169 kilómetros. Ya en 1889 se efectuaron varias conferencias para resolver los problemas internacionales originados por la aviación, pero hasta 1947 no se creó el primer organismo adecuado: la Organización de la Aviación Civil Internacional (OACI), adscrita a la ONU, con sede en Montreal (Canadá). Otra organización que surgió a partir de la iniciativa de las compañías aéreas es la Asociación Internacional del Transporte Aéreo (IATA), también con sede en Montreal y que agrupa a más de 100 empresas de transporte aéreo, por lo general de líneas regulares, unidas en este organismo para resolver sus problemas comunes. El gran desarrollo de la aviación a escala mundial ha obligado a todos los países a establecer leyes y regulaciones que permitan un eficiente y seguro tráfico aéreo y a firmar convenios y protocolos internacionales como el de Tokio en 1963 o el de La Haya en 1973. En la actualidad existen en la mayoría de las naciones leyes sobre la navegación aérea que junto con otras medidas han llevado a este medio de transporte a convertirse en uno de los más seguros y eficientes. LA ERA ESPACIAL: A principios de siglo, el maestro de escuela ruso Konstantin Eduardovisch Tsiolkovski ( 1857 – 1935) era considerado como un excéntrico cuyas teorías apenas tenían relación con la realidad. Sin embargo, la era espacial había nacido en la humilde morada que habitaba ese maestro, por lo que fue llamado el “padre de la astronáutica”. Aunque jamás lanzó un cohete, las contribuciones de Tsiolkovsky a la ciencia de la navegación espacial fueron inconmesurables. Ya en 1883 expuso los principios que permiten el desplazamiento de un cohete en el vacío, y en “Sueños de la Tierra y el Cielo”, publicado en Moscú en 1895, enunció las posibilidades de un satélite espacial. Más tarde, en 1903, comenzó a publicar por capítulos su libro “Exploración del espacio interplanetario mediante aparatos a reacción” que sentó la teoría del vuelo de los cohetes y las perspectivas de la navegación espacial. La contribución principal de Tsiolkovski consistió en recomendar la utilización de propulsores líquidos, que además de permitir prestaciones mejores que los sólidos, podrían controlarse con mayor facilidad tras la ignición. Ello resalta el elevado nivel de las ideas de Tsiolkovski; no obstante sus cuadernos de notas y obras impresas fueron completadas más adelante con nuevos conceptos que, de una u otra forma, se plasmarían en realizaciones técnicas prácticas. Consideró la posibilidad de controlar el vuelo de los cohetes en el exterior de la atmósfera mediante aletas situadas tras la tobera, o mediante la inclinación de la propia tobera. Apuntó la posibilidad de emplear combustibles de distintos tipos, como gasolina, queroseno, alcohol y metano; ideó diversos métodos para regular el flujo de los propulsores de la cámara de combustión, con la utilización de válvulas mezcladoras y recomendó la refrigeración de la cámara de combustión y de la tobera mediante el paso de uno de los líquidos a través de una camisa de doble pared. En sus primeros diseños de cabinas para naves espaciales tuvo presente las necesidades de los organismos vivientes, e incluyó dispositivos para absorber el dióxido de carbono y los olores; por otra parte, reconoció la importancia de que la tripulación se mantuviera en posición tendida, con la espalda apoyada sobre los motores, durante los momentos de aceleración. El problema de la aceleración en el vuelo en cohetes le preocupó de tal modo que incluso recomendó la inmersión de los pasajeros en un líquido de densidad igual a la del cuerpo humano. Propuso también la construcción de naves espaciales de doble pared, para conseguir protección suficiente frente al calentamiento y enfriamiento excesivos, y como medida de precaución ante la posibilidad de que un meteorito atravesara la pared exterior de la aeronave. Por otra parte, Tsiolkovski aconsejó aprovechar el oxígeno líquido de los depósitos de combustible para suministrar oxígeno gaseoso a la cabina presurizada, y también predijo que un hombre protegido por un traje espacial y sujeto por una especie de cadena podría salir al exterior de la nave y permanecer en el vacío. El precursor ruso consideró asimismo que podría aprovecharse el efecto giroscópico para estabilizar los cohetes en vuelo, y recomendó la utilización de cohetes de varias etapas o múltiples (que llamó “trenes de cohetes”), de modo que cada etapa se desprendiera del conjunto a medida que su combustible se agotara, como único medio para alcanzar la velocidad necesaria para el vuelo espacial. Tsiolkovski anticipó el desarrollo de estaciones espaciales y describió el traslado al espacio de componentes plegados para su posterior despliegue y montaje; asimismo predijo que llegaría el momento en que se contruirían estaciones espaciales en las cuales el oxígeno y la alimentación necesaria para los seres humanos se obtendría de la vegetación cultivada en las propias estaciones. En su escrito “El avión cohete” (1930) Tsiolkovski analizaba las ventajas e inconvenientes de los aviones cohete en relación con los propulsados a hélice para el vuelo de gran velocidad en la alta atmósfera. En 1909 el norteamericano Dr. Robert H. Goddard acometió una amplia investigación teórica sobre la dinámica de cohetes. Tres años después midió el empuje de uncohete de combustible sólido encendido en el interior de una cámara de vacío, con lo que probó la posibilidad de que los cohetes funcionaran en el espacio exterior. De este modo se abandonó definitivamente la creencia, hasta entonces muy arraigada, de que los cohetes únicamente podían funcionar en la atmósfera. Los trabajos posteriores del Dr. Goddard se orientaron al diseño de un cohete sonda práctico que permitiera obtener datos de las capas superiores de la atmósfera fuera del alcance de los aviones y globos sonda. Como Tsiolkovski, reconoció además las enormes posibilidades de los cohetes de combustible líquido. Su determinación le valdría un lugar imperecedero en la historia: el 16 de marzo de 1926 consiguió lanzar, en Auburn (Massachussets), el primer cohete de combustible líquido del mundo. Aquel pequeño ingenio (el biplano de los Wright de la astronáutica) realizó un corto vuelo de 56 m con una duración de 2,5 segundos; su velocidad media fue de 103 km/h. Esta proeza fue superada, por un escaso margen, por el alemán Johannes Winkler, que el 21 de febrero de 1931 lanzó un cohete cerca de Dessau; estaba propulsado por metano y oxígeno líquidos. Aunque en esa ocasión apenas superó los 3 m de altura, tres semanas después alcanzó una altura de 90 m, tras ser equipado con estabilizadores. El inventor alemán Max Valier, tras experimentar cohetes de combustible sólido en automóviles, trineos y vehículos en carriles, interesó en sus investigaciones al Dr. Paul Heylandt, dueño de una fábrica de gases industriales, que fabricaba oxígeno líquido. Aunque Valier no recibía un salario, fue autorizado a emplear un máximo de 6000 marcos en la construcción y experimentación de cohetes en dicha fábrica; no obstante, por razones de seguridad los ensayos únicamente tenían lugar de noche y en los fines de semana. Con la ayuda de Walter Riedel, uno de los ingenieros de la firma, Valier construyó y ensayó un pequeño motor con envoltura de acero. Valier creía que el camino hacia los viajes espaciales pasaría por una evolución gradual del automóvil cohete al avión cohete y luego a la nave espacial. Ello explica que Valier no se convirtiera en el primer europeo en lanzar un cohete de combustible líquido en vuelo libre. Se había propuesto ensayar sus cohetes en vehículos tripulados. Hermann Oberth , el inspirador de los trabajos alemanes sobre cohetes, era profesor de física y matemáticas. Nació en 1894 en Transilvania, actualmente integrada en Rumania. En 1923 publicó un reducido volumen titulado “Die Ratete zu den Planetraumen” (“ El cohete en el espacio interplanetario”), en el que además de sentar las bases del funcionamiento de los cohetes en el vacío afirmaba que, si se dispusiera de empuje suficiente, podrían fabricarse cohetes capaces de dar la vuelta a la Tierra. Oberth experimentó diversas combinaciones de propulsores. Quizá más significativo sea el hecho de que describiera con cierto detalle la forma de un cohete (le modelo B) que creía capaz de explorar las capas altas de la atmósfera. Aunque nunca se cinstruyó, el modelo B excitó la imaginación de otros adelantados, y en 1927 se formó un grupo de entusiastas conocido como “Verein Fur Raumschiffahert e. V.” Sociedad para la Navegación Espacial. La primera reunión tuvo lugar en una cervecería de Breslau y conduciría al desarrollo de técnicas que habrían de estremecer al mundo (pues la sociedad había de convertirse en la cuna de científicos que atravesaron por primera vez las fronteras del espacio). Entre los primeros miembros se encontraban Johannes Winkler, Max Valier, Willy Ley, Hermann Oberth, Rudolf Nebel, Walter Hohmann, Guido Von Pirquet, Eugen Sanger, Franz von Hoefft, Kurt Hainish, Klaus Riedel, Rolf Engel y Wernher von Braun quien ingresó en ella en 1930, a la edad de 18 años. Hitler, que había llegado al poder de Alemania en 1933, comenzaba a extender su influencia, y las fuerzas armadas vieron sus presupuestos engrosados. La Luftwaffe estaba interesada en instalar motores cohete en sus aviones, y el ejército en sus cohetes balísticos como medio para ampliar el alcance de la artillería convencional. Así pues, se decidió establecer un centro de investigaciones de cohetes en las proximidades de la localidad de Peenemunde, en la costa alemana del Báltico, donde podían lanzarse con seguridad a distancias superiores a los 300 Km. El enorme centro, cuya construcción se prolongó durante dos años, contaba con instalaciones de ensayo y laboratoriosperfectamente equipados, que poco tiempo atrás sus ocupantes no podían ni soñar. Von Braun reclutó a parte de los entusiastas que habían colaborado en los cohetes Mirak y Repulsor en el Raketenflugplatz. Fue en Peenemunde donde se completó el diseño del Cohete A-5 cuyos lanzamientos tuvieron lugar, sis sistemas de guiado, en 1938. El primer vuelo con control giroscópico completo tuvo lugar en el otoño de 1939 (al comienzo de la Segunda Guerra Mundial). Allí se probarían también los cohetes A-4, los cuales evolucionarían hacia los Cohetes V-1 y V-2, con los cuales se bombardeó Londres durante el conflicto bélico mundial. También los soviéticos progresaban en el dominio de la cohetería. El 17 de agosto de 1933 se lanzaba en Moscú el GIRD 09, que empleaba como propulsores oxígeno líquido y gasolina gelatinizada, y alcanzó una altura de unos 400 m. El GIRD X, primer cohete soviético de combustible enteramente líquido, alcanzó casi 80 m el 25 de noviembre de 1933. Debe señalarse que Goddard en Estados Unidos, a pesar de trabajar con fondos mucho más limitados, alcanzó también logros con cohetes girocontrolados, y resulta interesante comparar los progresos durante este periodo. El Ingeniero Norteamericano instaló en 1932 un giróscopo de 10,2 cm en un cohete, con su eje de giro en el eje longitudinal del segundo. El eje de giro del giróscopo permanecía vertical, y cuando el ingenio se desviaba 13 grados de la vertical se cerraban contactos eléctricos que desencadenaban una acción rectificadora: una de las cuatro aletas aerodinámicas se abría, y simultáneamente se interponía en el chorro de gases una de las cuatro aletas deflectoras. Aunque el primer lanzamiento, el 19 de abril de 1932, fracasó por la pérdida de empuje del motor, y, se alcanzó tan solo una altura de 40m aproximadamente, bastó para observar el efecto estabilizador del giróscopo. Cuando el equipo llegó al lugar en donde había caído el equipo, observó que los deflectores estaban intactos, indicio de que habían funcionado. En los años siguientes Goddard realizó nuevos progresos con los estabilizadores automáticos. Uno de sus cohetes, lanzado el 8 de marzo de 1935, contaba con un sencillo péndulo en lugar del giróscopo, que emitía señales correctas cuando el cohete se desviaba más de 10 grados de la vertical. Este cohete alcanzó una velocidad de 700 millas por hora y cayó a 9000 pies de la torre de lanzamiento. Este precursor norteamericano de la cohetería llegó aún más lejos. En el verano de 1937 lanzó con éxito un cohete en el que el control se efectuaba mediante una junta universal, y que alcanzó una altitud de 626 m, aunque el vuelo se malogró por la apertura prematura del paracaídas. Su longitud era de 5.6m y contaba con una pieza de cola móvil, depósitos de combustible sujetos mediante alambres y un barógrafo abordo. A fines de la Segunda Guerra Mundial, los aviones polimotores alcanzaban un techo de tan solo 10 Km, y los globos sonda científicos eran capaces de elevarse, en el mejor de los casos, únicamente a 32 km (en 1952 y posteriormente durante el Año Geofísico Internacional, se lanzaron en Estados Unidos cohetes sonda con instrumentos desde una altitud de 30 km, a la que fueron elevados los globos; estos ingenios conocidos como rockoons, trasladaron cargas de pago de 9kg a altitudes del orden de 100km). Al finalizar la guerra, los Estados Unidos y la Unión Soviética contaban ya con los medios necesarios para penetrar las capas superiores de la atmósfera y trasladar a ellas cargas de pago científicas considerables. Naturalmente se trataba del cohete V-2. En los últimos años de la guerra los alemanes habían trazado planes para emplear el V-2 con esos fines. El Instituto de Investigación de Física Estratosférica había desarrollado y ensayado instrumentos de medida especiales para registrar el espectro ultravioleta del Sol, las presiones atmosféricas y las temperaturas a diversas altitudes, el flujo de radiación cósmica y de otros tipos, y también un dispositivo para recoger muestras de aire. Se lanzaron dos mísiles sin instrumentos para verificar las características de vuelo en tales misiones. No obstante, las exigencias bélicas en las postrimerías de la guerra determinaron la suspensión de este programa planeado para el V-2. Con el fin de la guerra, los cohetes V-2 existentes y los componentes cayeron en manos de norteamericanos, soviéticos, franceses y británicos. Los primeros, y en menor medida los segundos, acometieron amplios programas para aprovechar el armamento capturado y alcanzar los objetivos que se había trazado los alemanes: la investigación científica de la alta atmósfera mediante cohetes capaces de alcanzar grandes altitudes. En el otoño de 1945 se habían embarcado en Alemania, con destino a los Estados Unidos, componentes para la fabricación de más de 100 V-2, que debían montarse y lanzarse en el nuevo campo de pruebas de White Sands, en Nuevo México. La finalidad primordial de estos misiles consistía en recoger datos sobre el entorno físico y las radiaciones de alta atmósfera, y en adiestrar a los norteamericanos, civiles y militares, en el montaje, comprobaciones y lanzamiento de cohetes de grandes proporciones. La familia de cohetes sonda engendrada por el V-2 de la Segunda Guerra Mundial fue la antecesora de proyectiles mucho más potentes, capaces de atravesar las fronteras del espacio y enviar robots de exploración. El año Geofísico Internacional vio nacer, además, un medio para estudiar el espacio fuera del alcance de los cohetes sonda y sus cargas de pago. Se trata del satélite científico, capaz de orbitar a altitudes en las cuales la colisión con las escasísimas moléculas de aire produce una resistencia despreciable. Tales observatorios científicos podrían permanecer en órbita durante años, con la única limitación de la vida operativa de los instrumentos científicos, de sus sistemas de telemetría y del suministro de energía. El concepto de satélite artificial se había considerado en Estados Unidos años atrás. En 1945 el Bureau of Aeronautics (administración de la aviación naval norteamericana) emprendió el estudio de un artefacto de este tipo con la finalidad de situar instrumentos científicos en el espacio. Un año más tarde la USAAF estudió un informe análogo elaborado por la Douglas Aircraft Company. Este documento contenía el diseño preliminar de una “nave espacial circunterrestre experimental”. Ya el 4 de octubre de 1951 M.K. Tijonrakov, uno de los principales diseñadores de cohetes soviéticos, afirmaba que la tecnología de su país estaba a la par con los Estados Unidos, y que era capaz de situar un satélite artificial en órbita alrededor de la Tierra. En el transcurso de la conferencia mundial para la paz que se celebraba en Viena, el 27 de noviembre de 1953 Alexander N. Nesmeianov, de la Academia de ciencias de la URSS declaró “ La creación de un satélite artificial de la Tierra constituye una posibilidad real”. Posteriormente, durante una conferencia del comité especial para el Año Geofísico Internacional que tenía lugar en Barcelona, el 11 de Septiembre de 1956 un delegado soviético declaró que su país situaría en orbita un satélite artificial ese mismo año. El 4 de Octubre de 1957 los }Estados Unidos y el mundo entero constataron con gran sorpresa que no se trataba de propaganda, sino de una realidad.. La USRR acababa de situar en órbita el Sputnik1, el primer satélite artificial de la Tierra. Se trataba de un satélite esférico con un diámetro de 58 cm y un peso de 83.6 kg. Contenía instrumentos para medir la densidad y la temperatura a lo largo de toda su órbita , que oscilaba entre 227 y 941 km. Por otra parte recogió datos sobre la concentración de electrones en la ionósfera. El 3 de noviembre los Soviéticos lanzaron el Sputnik 2. La carga de pago de 508 kg comprendía la perrita Laika e instrumentos para estudiar los efectos de la ingravidez en su cuerpo. Por otra parte portaba también sensores para medir el entorno de radiaciones en el espacio. Posteriormente los Estados Unidos lanzaron al espacio el Explorer 1, réplica norteamericana del Sputnik, un poco más pequeño y menos pesado. El valor científico del satélite radica en el descubrimiento de lo que luego se conocería como cinturones de Van Allen. Este episodio marcó uno de los hechos más interesantes de la Guerra Fría (y tal vez el verdadero legado de esa Guerra para la Humanidad), la Carrera Espacial entre los Estados Unidos y la Unión Soviética. Posteriormente se irían rompiendo marca por marca la salida del hombre al espacio y su llegada a la Luna, evento que divide la trascendencia tecnológica de la humanidad en dos, dando preponderancia a los desarrollos realizados por Estados Unidos a través de su agencia NASA. LA AUTOMATIZACIÓN INDUSTRIAL. La Automatización Industrial es la tecnología o conjunto de procesos o procedimientos que se llevan a cabo en una fábrica o industria determinada sin la intervención humana, únicamente con la acción directa de dispositivos eléctricos, neumáticos, mecánicos e hidráulicos. Esto se implementa utilizando un programa de instrucciones combinado con un sistema de control que ejecuta las instrucciones y un sistema de monitoreo que permanentemente le hace seguimiento a los procesos involucrados. Del Harder acuñó el término “Automatización” alrededor de 1946 para referirse a la gran cantidad de dispositivos automáticos que la Ford Motor Company había desarrollado en sus líneas de producción. La primera computadora electrónica digital fue desarrollada en la Universidad de Pensilvania en 1946. La primera máquina de control numérico computarizado fue desarrollada y probada in 1952 en el Instituto Tecnológico de Massachussets, basados en los conceptos presentados por Jhon Parsons y Frank Stulen. Más tarde en los años 60s y 70s, computadoras digitales empezaron a ser conectadas a máquinas herramientas. En 1954, el primer robot industrial fue desarrollado y patentado por George Devol. El primer robot comercial fue instalado para descargar partes en un proceso industrial de amoldamiento en 1961. En los 60s el primer sistema flexible de manufactura en Estados Unidos fue instalado por Ingersoll Rand Company para ejecutar operaciones de mecanizado en una gran variedad de piezas mecánicas. Cerca del año 1969 el primer controlador lógico programable fue introducido. En 1978, el primer computador personal comercial fue introducido por Apple Computer, sin embargo, un producto similar ya había sido introducido en forma de kit en 1975. El desarrollo de la tecnología del computador fue posible por los avances en electrónica, incluyendo el transistor (1948), el disco duro para la memoria del computador (1956), los circuitos integrados (1960), el microprocesador en 1971, las memorias RAM en 1984, chips de memoria en megas (1990), y los microprocesadores Pentium en 1993. El desarrollo del software con respecto a la automatización industrial ha sido también muy importante, incluyendo el desarrollo del lenguaje de programación FORTRAN (1955), el lenguaje para programación de máquinas herramientas con control numérico computarizado APT (1961), el sistema operativo UNÍS (1969), el lenguaje para programación de robots VAL (1979), Microsoft Windows (1985), y el lenguaje de programación JAVA (1995). Los avances y desarrollos en esta tecnología aún continúan. LA INTELIGENCIA ARTIFICIAL Evidencias del concepto de Inteligencia Artificial (IA) se encuentran desde el antiguo Egipto, pero con el desarrollo de computador electrónico en 1941, la tecnología finalmente podría hacer viable la creación de máquinas inteligentes. . El término Inteligencia Artificial (IA) fue inicialmente concebido en 1956, durante la Conferencia de Dartmouth, y desde ahí se ha venido desarrollando gracias a las teorías y principios propuestos por sus dedicados investigadores. Pese a su historia relativamente moderna, los avances en el campo de la IA han sido más bien pocos con respecto a lo inicialmente estimado. Desde su nacimiento hace cuatro (4) décadas, existe una gran variedad de programas en IA, los cuales han impactado otros avances tecnológicos. En 1941 una invención revolucionó cada aspecto del almacenamiento y procesamiento de la información. Esta invención, descubierta simultáneamente en Estados Unidos y Alemania, fue el computador electrónico. Los primeros computadores necesitaban grandes salones aislados con sistemas de aire acondicionado y muchos programadores para configurar miles de alambres para correr un programa. La innovación en 1949 fue el almacenamiento de programas, lo cual hizo el trabajo de programación más fácil. La invención de la electrónica significó el procesamiento de datos, lo cual sería el medio para hacer la IA posible. A pesar de que el computador poseía la tecnología necesaria para hacer la IA posible, no fue sino hasta la década de 1950 en el que la relación entre la inteligencia humana y las máquinas fue realmente observada. Norbert Wiener fue uno de los primeros Norteamericanos que realizó observaciones sobre el principio de retroalimentación. El ejemplo más familiar sobre el principio de retroalimentación es el termostato, el cual controla la temperatura interna de una casa cuando la compara con la temperatura externa del medio ambiente. Wiener llegó a la conclusión de que la inteligencia se basaba en mecanismos de retroalimentación. Mecanismos que pudieron ser simulados mediante máquinas. Este descubrimiento influyó enormemente en los primeros desarrollos de la IA. Más tarde en 1955, Newell y Simon desarrollaron La Teoría Lógica, considerada por muchos como el primer programa de IA. El programa representaba cada problema como un modelo en árbol y solucionaba el problema seleccionando la rama que más se ajustaba. Este programa constituyó la piedra angular para el desarrollo de la IA. En 1956 John McCarthy ( recordado como el padre de la IA ) organizó una conferencia para conocer el talento y la experiencia de otros investigadores en máquinas inteligentes. Un mes de lluvia de ideas sobre el tema. Dicha conferencia se denominó la “Reunión de Verano sobre proyectos de investigación en Inteligencia Artificial en Dartmouth”. Allí se acuñó el término Inteligencia Artificial. En los siete años siguientes a la conferencia, la IA siguió desarrollándose, pese a que algunas ideas formuladas en la conferencia fueron reexaminadas y reformuladas nuevamente. Centros de investigación en IA fueron formados en Carnegie Mellon y el MIT, concentrándose la investigación en la creación de sistemas que pudieran resolver problemas eficientemente y en la creación de sistemas que pudieran aprender de sí mismos. En 1957, la primera versión del nuevo programa “ El solucionador general de problemas” General Problem Solver (GPS) fue probado. El programa fue desarrollado por las mismas personas que elaboraron La Teoría Lógica. El GPS fue una extensión del principio de retroalimentación de Wiener y fue capaz de resolver una gran cantidad de problemas de sentido común. Un par de años después de GPS, IBM contrató un equipo de trabajo para investigar sobre IA. Herbert Gelerneter trabajó durante 3 años para desarrollar un programa que solucionara problemas geométricos. Cuando más programas se estaban desarrollando, McCarthy estaba ocupado desarrollando lo que sería el punto más trascendental en la historia de la IA. En 1958 McCarthy anuncia su nuevo descubrimiento; el lenguaje LISP, el cual continua utilizándose hoy en día. En 1963 MIT recibió 2.2 millones de dólares del gobierno de los Estados Unidos para ser utilizados en la investigación de IA con el ánimo de superar los avances tecnológicos logrados en la Unión Soviética. El proyecto sirvió para el desarrollo de la IA en paz en todo el mundo. En los siguientes años surgieron una gran cantidad de programas, uno de los más notables fue SHRDLU. SHRDLU formó parte del proyecto de micromundos, el cual consistió en una serie de programaciones realizadas sobre pequeños mundos ( como en el caso de un conjunto limitado de figuras geométricas ). Las investigaciones del MIT encabezadas por Marvin Minsky demostraron que cuando un grupo de objetos se encuentran confinados en un espacio reducido, los computadores pueden resolver problemas de lógica espacial. Otro de los programas que se desarrollaron más tarde en la década de 1960 fue STUDENT, el cual tenia la capacidad de resolver problemas de algebra y SIR el cual podía entender pequeñas frases en inglés. El resultado de estos programas fue el refinamiento de los lenguajes y la comprensión de la lógica. Otro avance en los 70s fue el advenimiento de los Sistemas Expertos. Los Sistemas Expertos predicen la probabilidad de solución de un problema bajo un conjunto de condiciones. Gracias a la capacidad que tienen actualmente los computadores para almacenar una gran cantidad de datos, los Sistemas Expertos tienen el potencial de interpretar estadísticas mediante la formulación de reglas. Las aplicaciones de los Sistemas Expertos se ampliaron en cosa de diez (10) años, hasta el punto de utilizarlos en estudio de mercados, mercados de acciones, diagnóstico médico y minería. Durante la década de 1970 fueron probados nuevos métodos de IA como por ejemplo la teoría marco de Minsky. También David Marr propuso nuevas teorías sobre la visión en máquinas, por ejemplo. investigó sobre cómo distinguir una imagen basado en la sombra de un objeto y la información básica sobre la forma, color y textura. Otro desarrollo durante esta época fue el lenguaje Prologue en 1972. Durante la década de 1980 se desarrolló a su más veloz paso y se introdujo en el sector corporativo. En 1986 las ventas en Estados Unidos relacionadas con Software y Hardware sobre IA alcanzaron la suma de 425 millones de dólares. Aumentaron las demandas de Sistemas Expertos debido a su eficiencia. Compañías como Digital Electronics utilizaron XCON, un sistema experto diseñado para programar computadores VAX. DuPont, General Motors y Boing adquirieron habilidad en el desarrollo de Sistemas Expertos. Teknoaledge y Intellicorp se especializaron en crear software para el desarrollo de Sistemas Expertos. Otros Sistemas Expertos fueron diseñados para optimizar otros Sistemas Expertos. Posteriormente surgieron fundaciones como la Asociación Americana de Inteligencia Artificial. Las empresas privadas empezaron a invertir enormes cantidades de dinero en el desarrollo de la IA; tal es el caso de DEC, que destinó 1 billón de dólares y 700 personas en sus investigaciones. Otros campos de la IA se desarrollaron durante la década de 1980. Uno en particular fue el campo de las máquinas de visión. Los trabajos de Minsky y Marr fueron implementados en las líneas de manufactura para realizar actividades de control de calidad. Para 1985, más de un centenar de compañías ofrecieron sistemas de visión en Estados Unidos, con unas ventas totales de 80 millones de dólares. Los años 80 no fueron totalmente buenos para la industria del IA. Para los años de 1986 y 1987 la demanda de sistemas IA decreció, y esta industria perdió más de medio billón de dólares. Compañías como Teknowledge y Intellicorp perdieron más de 6 millones de dólares. Estas pérdidas motivaron el recorte de presupuesto en investigaciones. Pese a estos sucesos, la IA se recupera lentamente. Nuevas tecnologías fueron desarrolladas en el Japón. Las técnicas de lógica difusa se popularizaron en Estados Unidos, gracias a su habilidad para tomar decisiones en situaciones inciertas. También se consideró el campo de las Redes Neuronales como un posible camino para desarrollar y hacer crecer la IA. Militarmente, la IA fue probada en la Guerra Tormenta del Desierto. Tecnologías basadas en IA fueron utilizadas en sistemas de misiles, sistemas de guía, etc. El crecimiento del interés público también se ha desarrollado. Aplicaciones para Apple Macintosh e IBM, sistemas para reconocimiento de voz ya son viables. Videograbadoras que utilizan lógica difusa, sistemas para almacenamiento de datos en computadoras también se pueden conseguir en el mercado. Inevitablemente la IA continuará desarrollándose y afectando nuestras vidas. LA ROBOTICA La palabra “ROBOT” fue acuñada en la obra de teatro de Checoslovaquia titulada “ Los robots universales de Rosum”, escrita por Karel Capek en los años 20. La palabra checa ROBOTA significa trabajo forzado. El primer inventor de robots fue el británico Cyril W Kenwared, quien desarrolló un manipulador con capacidad para moverse en un sistema cartesiano x,y,z. En 1954, Kenward patentó su desarrollo, el cual fue publicado en 1957. El segundo inventor fue un americano llamado Geroge C. Devol, quien es acreditado por dos inventos en la industria robótica. El primero de ellos fue un dispositivo magnético para grabar señales eléctricas, las cuales podían ser reproducidas para el control de máquinas en procesos industriales. Este dispositivo fue desarrollado alrededor de 1946 y la patente fue publicada en 1952. el segundo invento fue un dispositivo robótico desarrollado en 1950, que Devol denominó “ Artículo de Transferencia Programada” para ser utilizado en el ensamblaje de partes. Esta patente fue finalmente publicada en 1961. Este fue el primer prototipo de robots accionados hidráulicamente que posteriormente serían desarrollados por Unimation, Inc. Sin embargo, el robot de Kenward es considerado como el primero, pero el desarrollo de Devol aportó más a la industria y al desarrollo tecnológico y comercial de la robótica. Posteriormente Joseph Engelberg, quien había obtenido su grado en física en 1949, comenzó a trabajar en una compañía que fabricaba dispositivos de control para motores jet. En una fiesta en Fairfiel, Connecticut, Devol describió su “ Articulo de transferencia programada” a Engelberger y posteriormente manifestó su inquietud de comercializar el dispositivo. En 1962, Unimation Inc, fue fundada con Engelberger como presidente. El nombre del primer producto de la compañía fue “Unimate”, un robot de configuración polar, el cual fue utilizado en las líneas de ensamblaje de Ford Company. El Robot Institute of America define un robot como un manipulador programable diseñado para desplazar materiales, partes, herramientas o determinados artefactos mediante movimientos programados variables. Leyes de la robótica: Isaac Asimov, propuso en sus obras de ciencia ficción las siguientes leyes para un robot: 􀁺 Ley cero: Un robot no debe atentar contra la humanidad, o, por inacción permitir que la humanidad sea afectada. 􀁺 Ley uno: Un robot no lastimará a un ser humano, o, por inacción, permitir que un humano sea lastimado, a menos que esto viole una ley de mayor jerarquía. 􀁺 Ley dos: un robot debe obedecer órdenes dadas por humanos, excepto cuando estas órdenes entran en conflicto con una ley de mayor jerarquía. 􀁺 Ley tres: un robot debe proteger su propia existencia si no entra en conflicto con una ley de mayor jerarquía. PROCESOS MODERNOS Y MATERIALES INTELIGENTES: Históricamente, la mayoría de las aleaciones se preparaban mezclando los materiales fundidos. Más recientemente, la pulvimetalurgia ha alcanzado gran importancia en la preparación de aleaciones con características especiales. En este proceso, se preparan las aleaciones mezclando los materiales secos en polvo, prensándolos a alta presión y calentándolos después a temperaturas justo por debajo de sus puntos de fusión. El resultado es una aleación sólida y homogénea. Los productos hechos en serie pueden prepararse por esta técnica abaratando mucho su costo. Entre las aleaciones que pueden obtenerse por pulvimetalurgia están los cermets. Estas aleaciones de metal y carbono (carburos), boro (boruros), oxígeno (óxidos), silicio (siliciuros) y nitrógeno (nitruros) combinan las ventajas del compuesto cerámico, estabilidad y resistencia a las temperaturas elevadas y a la oxidación, con las ventajas del metal, ductilidad y resistencia a los golpes. Otra técnica de aleación es la implantación de ion, que ha sido adaptada de los procesos utilizados para fabricar chips de ordenadores o computadoras. Sobre los metales colocados en una cámara de vacío, se disparan haces de iones de carbono, nitrógeno y otros elementos para producir una capa de aleación fina y resistente sobre la superficie del metal. Bombardeando titanio con nitrógeno, por ejemplo, se puede producir una aleación idónea para los implantes de prótesis. La plata fina, el oro de 14 quilates, el oro blanco y el platino iridiado son aleaciones de metales preciosos. La aleación antifricción, el latón, el bronce, el metal Dow, la plata alemana, el bronce de cañón, el monel, el peltre y la soldadura son aleaciones de metales menos preciosos. Debido a sus impurezas, el aluminio comercial es en realidad una aleación. Las aleaciones de mercurio con otros metales se llaman amalgamas MICROMÁQUINAS Y NANOTECNOLOGIA:  El 29 de diciembre de 1959, el físico estadounidense Richard Feynman dio una conferencia ante la American Physical Society titulada “Hay mucho sitio en lo más bajo”. En aquella conferencia, Feynman trató sobre los beneficios que supondría para la sociedad el que fuéramos capaces de manipular la materia y fabricar artefactos con una precisión de unos pocos átomos, lo que corresponde a una dimensión de 1 nm, aproximadamente. Feynman pronosticó correctamente, por ejemplo, el impacto que tendría la miniaturización sobre las capacidades de los ordenadores electrónicos; también predijo el desarrollo de los métodos que se emplean en la actualidad para fabricar circuitos integrados, y la aparición de técnicas para trazar figuras extremadamente finas mediante haces de electrones. Incluso planteó la posibilidad de producir máquinas a escala molecular, que nos permitirían manipular moléculas. Cuarenta años después de aquella conferencia, los expertos que trabajan en el campo de la nanotecnología están empezando a poner en práctica algunas de las ideas propuestas originalmente por Feynman, y muchas más que no se previeron entonces. Para captar intuitivamente la longitud de un nanómetro, consideremos un cabello humano. Típicamente suele tener un espesor de unos 100 micrómetros (μm). Una bacteria normal es unas 100 veces más pequeña, con un diámetro de alrededor de 1 μm. Un virus del resfriado común es aproximadamente 10 veces menor, con un tamaño de unos 100 nm. Una proteína típica de las que componen la envoltura de dicho virus tiene unos 10 nm de espesor. Una distancia de 1 nm equivale a unos 10 diámetros atómicos, y corresponde a las dimensiones de uno de los aminoácidos que componen esa proteína. Por tanto, puede verse que 1 nm supone una tolerancia dimensional extremadamente pequeña, pero ya hay varias tecnologías que están próximas a alcanzarla. El término ‘nanotecnología’ fue acuñado por Nomo Taniguchi en 1974 en relación con la fabricación de productos mediante métodos de mecanizado. Taniguchi mostró cómo la tendencia a aumentar la precisión de fabricación estaba llevando inexorablemente al punto en que, en el año 2000, las piezas fabricadas con un mecanizado “normal” tendrían una precisión de 1 μm, mientras que el mecanizado “de precisión” supondría una precisión de 10 nm y el “ultrapreciso” de hasta 1 nm. Sus predicciones demostraron en muchos casos ser correctas. Este tipo de nanotecnología forma parte de un grupo denominado a menudo ‘nanotecnologías de arriba abajo’, que se acercan a la precisión necesaria gradualmente, sobre todo mediante refinamientos de métodos de fabricación anteriores. En 1964, Gordon Moore, de la empresa estadounidense Fairchild Semiconductor Corporation, predijo que el número de transistores que se podrían fabricar en un chip se duplicaría cada año. La llamada ‘ley de Moore’ sigue cumpliéndose de forma aproximada, aunque en la actualidad el número se duplica cada dos o tres años. La última tecnología en chips comerciales, como el Pentium de Intel, tiene una anchura de línea de unos 300 nm, con aproximadamente 1,5 millones de transistores en cada chip. Algunos dispositivos especializados, como los chips de memoria dinámica de acceso aleatorio (DRAM), que pueden almacenar hasta 64 millones de bits de información, tienen más de 64 millones de transistores. En los primeros años del siglo XXI, las anchuras de línea mínimas de los chips comerciales deberían disminuir hasta 100 o 200 nm en componentes como los chips de DRAM, que podrían almacenar más de 1.000 millones de bits. Algunos ejemplos de estos dispositivos, que se aproximan a la región de la nanotecnología, ya se han probado en el laboratorio. Y EL FUTURO... La problemática actual de la humanidad plantea grandes retos para la Ingeniería Mecánica. Por una parte, no existen procesos verdaderamente eficientes para tratamiento y manejo de agua potable, transporte de alimentos, manejo eficiente de energía eléctrica, hidráulica, eólica, térmica o generada por hidrocarburos. La Ingeniería Mecánica tenderá a asociarse con conceptos medioambientales y ecológicos para su desarrollo. La manipulación en las microestructuras de aleaciones producirá metales especiales, compuestos avanzados y materiales inteligentes que auto corrigen defectos, con grandes capacidades en resistencia mecánica, térmica y química. La corrosión se podrá manejar económicamente, y tal vez tienda a desaparecer. Se utilizarán nuevos combustibles, más económicos en su producción y menos contaminantes, lo que exige el desarrollo de motores adaptados para su uso. Las máquinas se asociarán más con el Ser Humano. El reemplazo de partes humanas como huesos por aleaciones especiales de Titanio, o cartílagos por mezcla de plástico y células vivas marcarán un hito en el desarrollo de la biomecánica. La exploración espacial seguirá a su ritmo, planteando más retos en cuanto al desarrollo de hábitats adecuados para la supervivencia de la humanidad en el espacio exterior. El uso seguro de la energía atómica y su masificación en todo el mundo será un hecho. La exploración y explotación del mar en todas sus dimensiones implica el desarrollo de artefactos y equipos capaces de trabajar sometidos a grandes presiones hidráulicas. El desarrollo de arcologías facilitará la construcción de colonias espaciales y submarinas. Nacerá la Industria de Gravedad Cero, la minería planetaria y de asteroides. Aprenderemos a manipular las estructuras atómicas de compuestos de diversos materiales para sacar de ellos el máximo provecho, hasta de la piedra misma. Tal vez volvamos al Sílex para transformarlo atómicamente y revelar su secreto, que fue el que nos sacó de las cavernas y nos impulsó al cielo. 